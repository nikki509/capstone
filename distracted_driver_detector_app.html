<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>distracted_driver_detector_app</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Machine-Learning-Engineer-Nanodegree">Machine Learning Engineer Nanodegree<a class="anchor-link" href="#Machine-Learning-Engineer-Nanodegree">&#182;</a></h1><h2 id="Capstone-Project">Capstone Project<a class="anchor-link" href="#Capstone-Project">&#182;</a></h2><h2 id="Project:-Write-an-Algorithm-for-Distracted-Driver-Detection">Project: Write an Algorithm for Distracted Driver Detection<a class="anchor-link" href="#Project:-Write-an-Algorithm-for-Distracted-Driver-Detection">&#182;</a></h2><hr>
<h3 id="The-Road-Ahead">The Road Ahead<a class="anchor-link" href="#The-Road-Ahead">&#182;</a></h3><p>The notebook is broken into separate steps as shown below.</p>
<ul>
<li><a href="#step0">Step 0</a>: Import Datasets</li>
<li><a href="#step1">Step 1</a>: Create a CNN to Classify Driver Images (from Scratch)</li>
<li><a href="#step2">Step 2</a>: Train a CNN with Transfer Learning - Part1 (Using the bottleneck features)</li>
<li><a href="#step3">Step 3</a>: Train a CNN with Transfer Learning - Part2 (Using Fine-tuning)</li>
<li><a href="#step4">Step 4</a>: Kaggle Results</li>
</ul>
<hr>
<p><a id='step0'></a></p>
<h2 id="Step-0:-Import-Datasets">Step 0: Import Datasets<a class="anchor-link" href="#Step-0:-Import-Datasets">&#182;</a></h2><h3 id="Import-Driver-Dataset">Import Driver Dataset<a class="anchor-link" href="#Import-Driver-Dataset">&#182;</a></h3><p>In the code cell below, we import a dataset of driver images.  We populate a few variables through the use of the <code>load_files</code> function from the scikit-learn library:</p>
<ul>
<li><code>train_files</code>, <code>valid_files</code>, <code>test_files</code> - numpy arrays containing file paths to images</li>
<li><code>train_targets</code>, <code>valid_targets</code>, <code>test_targets</code> - numpy arrays containing onehot-encoded classification labels </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_files</span>       
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># define function to load datasets</span>
<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">load_files</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">files</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;filenames&#39;</span><span class="p">])</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]),</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">files</span><span class="p">,</span> <span class="n">targets</span>

<span class="c1"># load train, test, and validation datasets</span>
<span class="n">train_files</span><span class="p">,</span> <span class="n">train_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;imgs_train/train&#39;</span><span class="p">)</span>
<span class="c1">#valid_files, valid_targets = load_dataset(&#39;dogImages/valid&#39;)</span>
<span class="n">test_files</span><span class="p">,</span> <span class="n">test_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;imgs_test&#39;</span><span class="p">)</span>

<span class="c1"># load list of names</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">17</span><span class="p">:</span><span class="mi">19</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;imgs_train/train/*/&quot;</span><span class="p">))]</span>

<span class="c1"># break training set into training and validation sets</span>
<span class="c1">#(train_files, valid_files) = train_files[:18000], train_files[18000:]</span>
<span class="c1">#(train_targets, valid_targets) = train_targets[:18000], train_targets[18000:]</span>
<span class="n">train_files</span><span class="p">,</span> <span class="n">valid_files</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> <span class="n">valid_targets</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_files</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># print statistics about the dataset</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%s</span><span class="s1"> total images.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">train_files</span><span class="p">,</span> <span class="n">valid_files</span><span class="p">,</span> <span class="n">test_files</span><span class="p">])))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> training images.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_files</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> total training categories.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> validation images.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_files</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> test images.&#39;</span><span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_files</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 102150 total images.

There are 17939 training images.
There are 10 total training categories.
There are 4485 validation images.
There are 79726 test images.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dataset-Exploration">Dataset Exploration<a class="anchor-link" href="#Dataset-Exploration">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;driver_imgs_list.csv&quot;</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="s1">&#39;infer&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;classname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Image Counts&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;classname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0    c0
1    c0
2    c0
Name: classname, dtype: object
count     22424
unique       10
top          c0
freq       2489
Name: classname, dtype: object

 Image Counts
c7    2002
c8    1911
c9    2129
c5    2312
c4    2326
c6    2325
c1    2267
c0    2489
c2    2317
c3    2346
Name: classname, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dataset-Visualization">Dataset Visualization<a class="anchor-link" href="#Dataset-Visualization">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># Pretty display for notebooks</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">nf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;classname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;classname&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nf</span><span class="p">)</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">1.5</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">ay</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">ay</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Bar Chart&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;classname&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABK0AAAHDCAYAAADm/+lfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pre-process-the-Data">Pre-process the Data<a class="anchor-link" href="#Pre-process-the-Data">&#182;</a></h3><p>When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape</p>
$$
(\text{nb_samples}, \text{rows}, \text{columns}, \text{channels}),
$$<p>where <code>nb_samples</code> corresponds to the total number of images (or samples), and <code>rows</code>, <code>columns</code>, and <code>channels</code> correspond to the number of rows, columns, and channels for each image, respectively.</p>
<p>The <code>path_to_tensor</code> function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape</p>
$$
(1, 224, 224, 3).
$$<p>The <code>paths_to_tensor</code> function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape</p>
$$
(\text{nb_samples}, 224, 224, 3).
$$<p>Here, <code>nb_samples</code> is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of <code>nb_samples</code> as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>                  
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="c1"># loads RGB image as PIL.Image.Image type</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
    <span class="c1"># convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="c1"># convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">paths_to_tensor</span><span class="p">(</span><span class="n">img_paths</span><span class="p">):</span>
    <span class="n">list_of_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">img_paths</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">list_of_tensors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step1'></a></p>
<h2 id="Step-1:-Create-a-CNN-to-Classify-Driver-Images-(from-Scratch)">Step 1: Create a CNN to Classify Driver Images (from Scratch)<a class="anchor-link" href="#Step-1:-Create-a-CNN-to-Classify-Driver-Images-(from-Scratch)">&#182;</a></h2><h3 id="Pre-process-the-Data">Pre-process the Data<a class="anchor-link" href="#Pre-process-the-Data">&#182;</a></h3><p>The images are rescaled by dividing every pixel in every image by 255. 0.5 is subtracted to ensure the mean is zero.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">ImageFile</span>                            
<span class="n">ImageFile</span><span class="o">.</span><span class="n">LOAD_TRUNCATED_IMAGES</span> <span class="o">=</span> <span class="bp">True</span>                 

<span class="c1"># pre-process the data for Keras</span>
<span class="n">train_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">train_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">valid_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">valid_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">test_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">test_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span> <span class="o">-</span> <span class="mf">0.5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 17939/17939 [01:30&lt;00:00, 197.83it/s]
100%|██████████| 4485/4485 [00:21&lt;00:00, 206.68it/s]
100%|██████████| 79726/79726 [06:41&lt;00:00, 198.39it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Model-Architecture">(IMPLEMENTATION) Model Architecture<a class="anchor-link" href="#(IMPLEMENTATION)-Model-Architecture">&#182;</a></h3><p>A CNN is created to classify driver images.  At the end of the code cell block, the layers of the model are summarized by executing the line:</p>

<pre><code>    model.summary()

</code></pre>
<p>We have created 4 convolutional layers with 4 max pooling layers in between. Filters were increased from 64 to 512 in each of the convolutional layers. Also dropout was used along with flattening layer before using the fully connected layer. Number of nodes in the last fully connected layer were setup as 10 along with softmax activation function. Relu activation function was used for all other layers.Xavier initialization was used in each of the layers.</p>
<p>4 convolutional layers were used to learn hierarchy of high level features. Max pooling layer is added to reduce the dimensionality. Flatten layer is added to reduce the matrix to row vector. This is because fully connected layer only accepts row vector. Dropout layers were added to reduce overfitting and ensure that the network generalizes well. The last fully connected layer with softmax activation function is added to obtain probabilities of the prediction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="c1">#model.add(GlobalAveragePooling1D())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>

<span class="c1">### TODO: Define your architecture.</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 224, 224, 64)      832       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 112, 112, 128)     32896     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 56, 256)       131328    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 28, 28, 512)       524800    
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 14, 14, 512)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 100352)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 500)               50176500  
_________________________________________________________________
dropout_2 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5010      
=================================================================
Total params: 50,871,366
Trainable params: 50,871,366
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Train-the-Model">(IMPLEMENTATION) Train the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Train-the-Model">&#182;</a></h3><p>The model is trained in the code cell below. Model checkpointing is used to save the model that attains the best validation loss.</p>
<p>Augmentation i.e. <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">augment the training data</a>, can also be used as per the need.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>  

<span class="c1">### TODO: specify the number of epochs that you would like to use to train the model.</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>

<span class="c1">### Do NOT modify the code below this line.</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;saved_models/weights.best.from_scratch.hdf5&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_tensors</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_tensors</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 17939 samples, validate on 4485 samples
Epoch 1/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.8611 - acc: 0.7150Epoch 00000: val_loss improved from inf to 0.14672, saving model to saved_models/weights.best.from_scratch.hdf5
17939/17939 [==============================] - 306s - loss: 0.8603 - acc: 0.7153 - val_loss: 0.1467 - val_acc: 0.9565
Epoch 2/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1402 - acc: 0.9576Epoch 00001: val_loss improved from 0.14672 to 0.05218, saving model to saved_models/weights.best.from_scratch.hdf5
17939/17939 [==============================] - 246s - loss: 0.1401 - acc: 0.9577 - val_loss: 0.0522 - val_acc: 0.9844
Epoch 3/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0790 - acc: 0.9772Epoch 00002: val_loss did not improve
17939/17939 [==============================] - 242s - loss: 0.0795 - acc: 0.9771 - val_loss: 0.0548 - val_acc: 0.9846
Epoch 4/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0560 - acc: 0.9838Epoch 00003: val_loss improved from 0.05218 to 0.02773, saving model to saved_models/weights.best.from_scratch.hdf5
17939/17939 [==============================] - 245s - loss: 0.0559 - acc: 0.9838 - val_loss: 0.0277 - val_acc: 0.9931
Epoch 5/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0492 - acc: 0.9868Epoch 00004: val_loss improved from 0.02773 to 0.02529, saving model to saved_models/weights.best.from_scratch.hdf5
17939/17939 [==============================] - 244s - loss: 0.0491 - acc: 0.9868 - val_loss: 0.0253 - val_acc: 0.9926
Epoch 6/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0443 - acc: 0.9885Epoch 00005: val_loss did not improve
17939/17939 [==============================] - 241s - loss: 0.0442 - acc: 0.9885 - val_loss: 0.0338 - val_acc: 0.9918
Epoch 7/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0473 - acc: 0.9872Epoch 00006: val_loss improved from 0.02529 to 0.01881, saving model to saved_models/weights.best.from_scratch.hdf5
17939/17939 [==============================] - 244s - loss: 0.0473 - acc: 0.9872 - val_loss: 0.0188 - val_acc: 0.9960
Epoch 8/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0456 - acc: 0.9882Epoch 00007: val_loss did not improve
17939/17939 [==============================] - 241s - loss: 0.0455 - acc: 0.9882 - val_loss: 0.0303 - val_acc: 0.9935
Epoch 9/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0514 - acc: 0.9885Epoch 00008: val_loss did not improve
17939/17939 [==============================] - 241s - loss: 0.0513 - acc: 0.9885 - val_loss: 0.0266 - val_acc: 0.9944
Epoch 10/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0399 - acc: 0.9898Epoch 00009: val_loss did not improve
17939/17939 [==============================] - 241s - loss: 0.0400 - acc: 0.9897 - val_loss: 0.0289 - val_acc: 0.9931
Epoch 11/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0429 - acc: 0.9892Epoch 00010: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0428 - acc: 0.9892 - val_loss: 0.0244 - val_acc: 0.9933
Epoch 12/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0496 - acc: 0.9887Epoch 00011: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0495 - acc: 0.9887 - val_loss: 0.0220 - val_acc: 0.9949
Epoch 13/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0382 - acc: 0.9911Epoch 00012: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0381 - acc: 0.9911 - val_loss: 0.0218 - val_acc: 0.9960
Epoch 14/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0475 - acc: 0.9892Epoch 00013: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0475 - acc: 0.9892 - val_loss: 0.0655 - val_acc: 0.9913
Epoch 15/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0457 - acc: 0.9893Epoch 00014: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0457 - acc: 0.9894 - val_loss: 0.0417 - val_acc: 0.9938
Epoch 16/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0491 - acc: 0.9895Epoch 00015: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0491 - acc: 0.9895 - val_loss: 0.0515 - val_acc: 0.9920
Epoch 17/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0449 - acc: 0.9893Epoch 00016: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0449 - acc: 0.9893 - val_loss: 0.0352 - val_acc: 0.9953
Epoch 18/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0556 - acc: 0.9887Epoch 00017: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0556 - acc: 0.9887 - val_loss: 0.0312 - val_acc: 0.9958
Epoch 19/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0514 - acc: 0.9898Epoch 00018: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0518 - acc: 0.9897 - val_loss: 0.0471 - val_acc: 0.9915
Epoch 20/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0589 - acc: 0.9900Epoch 00019: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0589 - acc: 0.9900 - val_loss: 0.0197 - val_acc: 0.9975
Epoch 21/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0500 - acc: 0.9898Epoch 00020: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0499 - acc: 0.9898 - val_loss: 0.0209 - val_acc: 0.9971
Epoch 22/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0613 - acc: 0.9893Epoch 00021: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0612 - acc: 0.9893 - val_loss: 0.0295 - val_acc: 0.9960
Epoch 23/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0689 - acc: 0.9890Epoch 00022: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0689 - acc: 0.9890 - val_loss: 0.1085 - val_acc: 0.9891
Epoch 24/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0782 - acc: 0.9876Epoch 00023: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0781 - acc: 0.9875 - val_loss: 0.0493 - val_acc: 0.9951
Epoch 25/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0667 - acc: 0.9889Epoch 00024: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0667 - acc: 0.9889 - val_loss: 0.0488 - val_acc: 0.9922
Epoch 26/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0650 - acc: 0.9893Epoch 00025: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0650 - acc: 0.9894 - val_loss: 0.0343 - val_acc: 0.9931
Epoch 27/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0670 - acc: 0.9898Epoch 00026: val_loss did not improve
17939/17939 [==============================] - 239s - loss: 0.0670 - acc: 0.9899 - val_loss: 0.0418 - val_acc: 0.9944
Epoch 28/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1044 - acc: 0.9877Epoch 00027: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.1043 - acc: 0.9877 - val_loss: 0.0277 - val_acc: 0.9960
Epoch 29/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0783 - acc: 0.9893Epoch 00028: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0782 - acc: 0.9894 - val_loss: 0.0514 - val_acc: 0.9944
Epoch 30/30
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0763 - acc: 0.9890Epoch 00029: val_loss did not improve
17939/17939 [==============================] - 240s - loss: 0.0762 - acc: 0.9890 - val_loss: 0.0437 - val_acc: 0.9946
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[7]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7f7d6564edd8&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/weights.best.from_scratch.hdf5&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">test_files_final</span> <span class="o">=</span> <span class="p">[</span><span class="n">item_test</span><span class="p">[</span><span class="mi">15</span><span class="p">:]</span> <span class="k">for</span> <span class="n">item_test</span> <span class="ow">in</span> <span class="n">test_files</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>The model is tried on the test dataset of driver images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># get index of predicted dog breed for each image in test set</span>
<span class="c1">#dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">test_tensors</span><span class="p">]</span>


<span class="c1"># report test accuracy</span>
<span class="c1">#test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)</span>
<span class="c1">#print(&#39;Test accuracy: %.4f%%&#39; % test_accuracy)</span>


<span class="c1">#subm = np.stack([test_files_final,predictions],axis=1)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">subm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_files_final</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">subm</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[&#39;img_49454.jpg&#39; &#39;0.005046165082603693&#39; &#39;1.0529247447266243e-05&#39;
  &#39;2.0024856439704308e-07&#39; &#39;0.00028800248401239514&#39; &#39;0.0030965458136051893&#39;
  &#39;0.0002922963467426598&#39; &#39;3.092297447437886e-06&#39; &#39;2.205350256190286e-06&#39;
  &#39;0.003186901332810521&#39; &#39;0.9880741238594055&#39;]
 [&#39;img_94120.jpg&#39; &#39;0.00017714709974825382&#39; &#39;4.952320331597093e-09&#39;
  &#39;6.329239113256335e-06&#39; &#39;3.2624741796993817e-10&#39; &#39;4.434001610320593e-09&#39;
  &#39;1.032989803206874e-05&#39; &#39;4.613828252786334e-08&#39; &#39;0.9997918009757996&#39;
  &#39;1.2984853583475342e-06&#39; &#39;1.3011300325160846e-05&#39;]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kaggle-Submission">Kaggle Submission<a class="anchor-link" href="#Kaggle-Submission">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/submission.csv&#39;</span><span class="p">,</span><span class="n">subm</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">comments</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>  <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">FileLink</span>
<span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/submission.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[13]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<a href='kaggle_submissions/submission.csv' target='_blank'>kaggle_submissions/submission.csv</a><br>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The submission resulted in Public Score of 2.67118. This can result in rank of 1362 out of 1440 in Public Leaderboard i.e. in top 94.58%</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step2'></a></p>
<h2 id="Step-2:-Train-a-CNN-with-Transfer-Learning---Part1">Step 2: Train a CNN with Transfer Learning - Part1<a class="anchor-link" href="#Step-2:-Train-a-CNN-with-Transfer-Learning---Part1">&#182;</a></h2><p>To reduce training time without sacrificing accuracy, a CNN is trained using transfer learning.</p>
<h3 id="Using-the-bottleneck-features-of-a-pre-trained-network">Using the bottleneck features of a pre-trained network<a class="anchor-link" href="#Using-the-bottleneck-features-of-a-pre-trained-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Obtain-Bottleneck-Features">Obtain Bottleneck Features<a class="anchor-link" href="#Obtain-Bottleneck-Features">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">VGG16</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, None, None, 3)     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">bottleneck_features_train_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">train_tensors</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#bottleneck_features_train_VGG16 = model.predict_generator(generator, nb_train_samples // batch_size)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_train_VGG16.npy&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">),</span><span class="n">bottleneck_features_train_VGG16</span><span class="p">)</span>


<span class="n">bottleneck_features_valid_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">valid_tensors</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#bottleneck_features_train_VGG16 = model.predict_generator(generator, nb_train_samples // batch_size)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_valid_VGG16.npy&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">),</span><span class="n">bottleneck_features_valid_VGG16</span><span class="p">)</span>


<span class="n">bottleneck_features_test_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">test_tensors</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_test_VGG16.npy&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">),</span><span class="n">bottleneck_features_test_VGG16</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">bottleneck_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/DogVGG16Data.npz&#39;</span><span class="p">)</span>
<span class="n">train_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
<span class="n">valid_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">]</span>
<span class="n">test_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">bottleneck_features_train_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">bottleneck_features_valid_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">bottleneck_features_test_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(17939, 7, 7, 512)
(4485, 7, 7, 512)
(79726, 7, 7, 512)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Architecture1">Model Architecture1<a class="anchor-link" href="#Model-Architecture1">&#182;</a></h3><p>The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each driver category and is equipped with a softmax.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">VGG16_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">bottleneck_features_train_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">VGG16_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>

<span class="n">VGG16_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d_2 ( (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                5130      
=================================================================
Total params: 5,130
Trainable params: 5,130
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-the-Model">Train the Model<a class="anchor-link" href="#Train-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_transfer_learning&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">VGG16_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bottleneck_features_train_VGG16</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">bottleneck_features_valid_VGG16</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 17939 samples, validate on 4485 samples
Epoch 1/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 2.0647 - acc: 0.3629Epoch 00000: val_loss improved from inf to 1.83891, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 2.0640 - acc: 0.3635 - val_loss: 1.8389 - val_acc: 0.4916
Epoch 2/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 1.6720 - acc: 0.5993Epoch 00001: val_loss improved from 1.83891 to 1.52233, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 1.6718 - acc: 0.5994 - val_loss: 1.5223 - val_acc: 0.6553
Epoch 3/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 1.4062 - acc: 0.7006Epoch 00002: val_loss improved from 1.52233 to 1.30828, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 1.4050 - acc: 0.7011 - val_loss: 1.3083 - val_acc: 0.7041
Epoch 4/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 1.2111 - acc: 0.7550Epoch 00003: val_loss improved from 1.30828 to 1.13829, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 1.2105 - acc: 0.7553 - val_loss: 1.1383 - val_acc: 0.7670
Epoch 5/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 1.0652 - acc: 0.7947Epoch 00004: val_loss improved from 1.13829 to 1.00286, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 1.0649 - acc: 0.7950 - val_loss: 1.0029 - val_acc: 0.8107
Epoch 6/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.9489 - acc: 0.8183Epoch 00005: val_loss improved from 1.00286 to 0.89713, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.9485 - acc: 0.8183 - val_loss: 0.8971 - val_acc: 0.8348
Epoch 7/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.8545 - acc: 0.8403Epoch 00006: val_loss improved from 0.89713 to 0.81219, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.8543 - acc: 0.8403 - val_loss: 0.8122 - val_acc: 0.8508
Epoch 8/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.7787 - acc: 0.8533Epoch 00007: val_loss improved from 0.81219 to 0.74231, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.7785 - acc: 0.8534 - val_loss: 0.7423 - val_acc: 0.8627
Epoch 9/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.7135 - acc: 0.8668Epoch 00008: val_loss improved from 0.74231 to 0.69014, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.7131 - acc: 0.8670 - val_loss: 0.6901 - val_acc: 0.8682
Epoch 10/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.6585 - acc: 0.8790Epoch 00009: val_loss improved from 0.69014 to 0.63645, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.6587 - acc: 0.8789 - val_loss: 0.6365 - val_acc: 0.8905
Epoch 11/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.6130 - acc: 0.8860Epoch 00010: val_loss improved from 0.63645 to 0.59603, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.6122 - acc: 0.8864 - val_loss: 0.5960 - val_acc: 0.8903
Epoch 12/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.5717 - acc: 0.8937Epoch 00011: val_loss improved from 0.59603 to 0.55391, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.5717 - acc: 0.8938 - val_loss: 0.5539 - val_acc: 0.8932
Epoch 13/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.5353 - acc: 0.9026Epoch 00012: val_loss improved from 0.55391 to 0.51687, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.5353 - acc: 0.9026 - val_loss: 0.5169 - val_acc: 0.9057
Epoch 14/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.5046 - acc: 0.9057Epoch 00013: val_loss improved from 0.51687 to 0.48481, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.5043 - acc: 0.9058 - val_loss: 0.4848 - val_acc: 0.9097
Epoch 15/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.4774 - acc: 0.9115Epoch 00014: val_loss improved from 0.48481 to 0.46939, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.4770 - acc: 0.9117 - val_loss: 0.4694 - val_acc: 0.9084
Epoch 16/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.4519 - acc: 0.9166Epoch 00015: val_loss improved from 0.46939 to 0.44187, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.4520 - acc: 0.9164 - val_loss: 0.4419 - val_acc: 0.9177
Epoch 17/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.4305 - acc: 0.9197Epoch 00016: val_loss improved from 0.44187 to 0.42105, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.4302 - acc: 0.9198 - val_loss: 0.4211 - val_acc: 0.9186
Epoch 18/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.4093 - acc: 0.9246Epoch 00017: val_loss improved from 0.42105 to 0.40389, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.4095 - acc: 0.9245 - val_loss: 0.4039 - val_acc: 0.9260
Epoch 19/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.3915 - acc: 0.9276Epoch 00018: val_loss improved from 0.40389 to 0.38952, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.3915 - acc: 0.9275 - val_loss: 0.3895 - val_acc: 0.9197
Epoch 20/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.3756 - acc: 0.9296Epoch 00019: val_loss improved from 0.38952 to 0.37208, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.3751 - acc: 0.9298 - val_loss: 0.3721 - val_acc: 0.9293
Epoch 21/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.3604 - acc: 0.9321Epoch 00020: val_loss improved from 0.37208 to 0.35270, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.3607 - acc: 0.9319 - val_loss: 0.3527 - val_acc: 0.9329
Epoch 22/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.3467 - acc: 0.9344Epoch 00021: val_loss improved from 0.35270 to 0.34276, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.3465 - acc: 0.9344 - val_loss: 0.3428 - val_acc: 0.9338
Epoch 23/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.3334 - acc: 0.9366Epoch 00022: val_loss improved from 0.34276 to 0.33295, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.3328 - acc: 0.9367 - val_loss: 0.3330 - val_acc: 0.9409
Epoch 24/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.3216 - acc: 0.9382Epoch 00023: val_loss improved from 0.33295 to 0.31651, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.3219 - acc: 0.9380 - val_loss: 0.3165 - val_acc: 0.9396
Epoch 25/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.3110 - acc: 0.9404Epoch 00024: val_loss improved from 0.31651 to 0.30703, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.3109 - acc: 0.9405 - val_loss: 0.3070 - val_acc: 0.9387
Epoch 26/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.3012 - acc: 0.9422Epoch 00025: val_loss improved from 0.30703 to 0.29385, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.3007 - acc: 0.9423 - val_loss: 0.2938 - val_acc: 0.9425
Epoch 27/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.2910 - acc: 0.9436Epoch 00026: val_loss improved from 0.29385 to 0.28642, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2912 - acc: 0.9435 - val_loss: 0.2864 - val_acc: 0.9460
Epoch 28/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.2827 - acc: 0.9440Epoch 00027: val_loss improved from 0.28642 to 0.27781, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2826 - acc: 0.9439 - val_loss: 0.2778 - val_acc: 0.9454
Epoch 29/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.2742 - acc: 0.9468Epoch 00028: val_loss improved from 0.27781 to 0.27216, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2742 - acc: 0.9469 - val_loss: 0.2722 - val_acc: 0.9469
Epoch 30/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2667 - acc: 0.9465Epoch 00029: val_loss improved from 0.27216 to 0.25916, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2668 - acc: 0.9465 - val_loss: 0.2592 - val_acc: 0.9501
Epoch 31/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2593 - acc: 0.9487Epoch 00030: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.2592 - acc: 0.9487 - val_loss: 0.2598 - val_acc: 0.9480
Epoch 32/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.2525 - acc: 0.9504Epoch 00031: val_loss improved from 0.25916 to 0.24771, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2526 - acc: 0.9504 - val_loss: 0.2477 - val_acc: 0.9496
Epoch 33/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.2462 - acc: 0.9516Epoch 00032: val_loss improved from 0.24771 to 0.24715, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2462 - acc: 0.9516 - val_loss: 0.2471 - val_acc: 0.9465
Epoch 34/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.2408 - acc: 0.9526Epoch 00033: val_loss improved from 0.24715 to 0.23568, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2407 - acc: 0.9527 - val_loss: 0.2357 - val_acc: 0.9507
Epoch 35/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2343 - acc: 0.9537Epoch 00034: val_loss improved from 0.23568 to 0.23409, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2343 - acc: 0.9537 - val_loss: 0.2341 - val_acc: 0.9534
Epoch 36/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.2293 - acc: 0.9544Epoch 00035: val_loss improved from 0.23409 to 0.22492, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2294 - acc: 0.9543 - val_loss: 0.2249 - val_acc: 0.9559
Epoch 37/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.2241 - acc: 0.9551Epoch 00036: val_loss improved from 0.22492 to 0.22115, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2243 - acc: 0.9550 - val_loss: 0.2212 - val_acc: 0.9574
Epoch 38/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2198 - acc: 0.9560Epoch 00037: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.2198 - acc: 0.9560 - val_loss: 0.2221 - val_acc: 0.9530
Epoch 39/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.2148 - acc: 0.9560Epoch 00038: val_loss improved from 0.22115 to 0.21467, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2149 - acc: 0.9558 - val_loss: 0.2147 - val_acc: 0.9545
Epoch 40/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.2107 - acc: 0.9575Epoch 00039: val_loss improved from 0.21467 to 0.20833, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.2106 - acc: 0.9575 - val_loss: 0.2083 - val_acc: 0.9545
Epoch 41/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.2068 - acc: 0.9578Epoch 00040: val_loss improved from 0.20833 to 0.20481, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.2066 - acc: 0.9579 - val_loss: 0.2048 - val_acc: 0.9579
Epoch 42/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.2027 - acc: 0.9586Epoch 00041: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.2027 - acc: 0.9587 - val_loss: 0.2077 - val_acc: 0.9550
Epoch 43/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1991 - acc: 0.9599Epoch 00042: val_loss improved from 0.20481 to 0.20144, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1993 - acc: 0.9598 - val_loss: 0.2014 - val_acc: 0.9570
Epoch 44/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1952 - acc: 0.9603Epoch 00043: val_loss improved from 0.20144 to 0.19747, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1951 - acc: 0.9603 - val_loss: 0.1975 - val_acc: 0.9583
Epoch 45/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1920 - acc: 0.9609Epoch 00044: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1921 - acc: 0.9609 - val_loss: 0.2033 - val_acc: 0.9603
Epoch 46/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1889 - acc: 0.9608Epoch 00045: val_loss improved from 0.19747 to 0.18833, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1887 - acc: 0.9609 - val_loss: 0.1883 - val_acc: 0.9588
Epoch 47/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1855 - acc: 0.9620Epoch 00046: val_loss improved from 0.18833 to 0.18571, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1855 - acc: 0.9620 - val_loss: 0.1857 - val_acc: 0.9605
Epoch 48/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1825 - acc: 0.9625Epoch 00047: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1822 - acc: 0.9624 - val_loss: 0.1870 - val_acc: 0.9588
Epoch 49/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1792 - acc: 0.9643Epoch 00048: val_loss improved from 0.18571 to 0.18181, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1793 - acc: 0.9643 - val_loss: 0.1818 - val_acc: 0.9621
Epoch 50/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1766 - acc: 0.9632Epoch 00049: val_loss improved from 0.18181 to 0.17893, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1767 - acc: 0.9632 - val_loss: 0.1789 - val_acc: 0.9630
Epoch 51/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1740 - acc: 0.9641Epoch 00050: val_loss improved from 0.17893 to 0.17376, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1741 - acc: 0.9641 - val_loss: 0.1738 - val_acc: 0.9639
Epoch 52/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1712 - acc: 0.9643Epoch 00051: val_loss improved from 0.17376 to 0.17256, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1713 - acc: 0.9643 - val_loss: 0.1726 - val_acc: 0.9652
Epoch 53/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1692 - acc: 0.9645Epoch 00052: val_loss improved from 0.17256 to 0.17007, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1691 - acc: 0.9645 - val_loss: 0.1701 - val_acc: 0.9637
Epoch 54/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.1659 - acc: 0.9653Epoch 00053: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1660 - acc: 0.9653 - val_loss: 0.1708 - val_acc: 0.9632
Epoch 55/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1638 - acc: 0.9658Epoch 00054: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1639 - acc: 0.9657 - val_loss: 0.1732 - val_acc: 0.9628
Epoch 56/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1616 - acc: 0.9656Epoch 00055: val_loss improved from 0.17007 to 0.16529, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1619 - acc: 0.9655 - val_loss: 0.1653 - val_acc: 0.9634
Epoch 57/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1601 - acc: 0.9661Epoch 00056: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1596 - acc: 0.9663 - val_loss: 0.1662 - val_acc: 0.9621
Epoch 58/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1578 - acc: 0.9659Epoch 00057: val_loss improved from 0.16529 to 0.16305, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1577 - acc: 0.9659 - val_loss: 0.1630 - val_acc: 0.9634
Epoch 59/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1554 - acc: 0.9672Epoch 00058: val_loss improved from 0.16305 to 0.16189, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1556 - acc: 0.9672 - val_loss: 0.1619 - val_acc: 0.9634
Epoch 60/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1537 - acc: 0.9672Epoch 00059: val_loss improved from 0.16189 to 0.15839, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1537 - acc: 0.9672 - val_loss: 0.1584 - val_acc: 0.9659
Epoch 61/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1517 - acc: 0.9680Epoch 00060: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1514 - acc: 0.9682 - val_loss: 0.1600 - val_acc: 0.9632
Epoch 62/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1500 - acc: 0.9682Epoch 00061: val_loss improved from 0.15839 to 0.15189, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1496 - acc: 0.9683 - val_loss: 0.1519 - val_acc: 0.9661
Epoch 63/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1480 - acc: 0.9686Epoch 00062: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1479 - acc: 0.9686 - val_loss: 0.1556 - val_acc: 0.9670
Epoch 64/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1458 - acc: 0.9692Epoch 00063: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1456 - acc: 0.9693 - val_loss: 0.1547 - val_acc: 0.9654
Epoch 65/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1442 - acc: 0.9698Epoch 00064: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1442 - acc: 0.9698 - val_loss: 0.1535 - val_acc: 0.9639
Epoch 66/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1430 - acc: 0.9698Epoch 00065: val_loss improved from 0.15189 to 0.14921, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1429 - acc: 0.9698 - val_loss: 0.1492 - val_acc: 0.9679
Epoch 67/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1417 - acc: 0.9700Epoch 00066: val_loss improved from 0.14921 to 0.14502, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1414 - acc: 0.9702 - val_loss: 0.1450 - val_acc: 0.9690
Epoch 68/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1398 - acc: 0.9697Epoch 00067: val_loss improved from 0.14502 to 0.14244, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1395 - acc: 0.9697 - val_loss: 0.1424 - val_acc: 0.9679
Epoch 69/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1377 - acc: 0.9708Epoch 00068: val_loss improved from 0.14244 to 0.14215, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1377 - acc: 0.9708 - val_loss: 0.1422 - val_acc: 0.9686
Epoch 70/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1368 - acc: 0.9715Epoch 00069: val_loss improved from 0.14215 to 0.13981, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1368 - acc: 0.9715 - val_loss: 0.1398 - val_acc: 0.9699
Epoch 71/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1352 - acc: 0.9719Epoch 00070: val_loss improved from 0.13981 to 0.13892, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1352 - acc: 0.9719 - val_loss: 0.1389 - val_acc: 0.9697
Epoch 72/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.1340 - acc: 0.9711Epoch 00071: val_loss improved from 0.13892 to 0.13802, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1346 - acc: 0.9708 - val_loss: 0.1380 - val_acc: 0.9712
Epoch 73/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1325 - acc: 0.9716Epoch 00072: val_loss improved from 0.13802 to 0.13740, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1329 - acc: 0.9716 - val_loss: 0.1374 - val_acc: 0.9688
Epoch 74/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1311 - acc: 0.9726Epoch 00073: val_loss improved from 0.13740 to 0.13657, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1311 - acc: 0.9726 - val_loss: 0.1366 - val_acc: 0.9686
Epoch 75/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1302 - acc: 0.9712Epoch 00074: val_loss improved from 0.13657 to 0.13542, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1300 - acc: 0.9712 - val_loss: 0.1354 - val_acc: 0.9666
Epoch 76/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1285 - acc: 0.9718Epoch 00075: val_loss improved from 0.13542 to 0.13231, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1287 - acc: 0.9717 - val_loss: 0.1323 - val_acc: 0.9706
Epoch 77/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1274 - acc: 0.9732Epoch 00076: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1272 - acc: 0.9732 - val_loss: 0.1339 - val_acc: 0.9677
Epoch 78/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1263 - acc: 0.9733Epoch 00077: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1264 - acc: 0.9731 - val_loss: 0.1357 - val_acc: 0.9690
Epoch 79/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1252 - acc: 0.9736Epoch 00078: val_loss improved from 0.13231 to 0.13018, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1252 - acc: 0.9736 - val_loss: 0.1302 - val_acc: 0.9710
Epoch 80/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1243 - acc: 0.9735Epoch 00079: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1242 - acc: 0.9734 - val_loss: 0.1308 - val_acc: 0.9692
Epoch 81/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1226 - acc: 0.9733Epoch 00080: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1225 - acc: 0.9733 - val_loss: 0.1332 - val_acc: 0.9679
Epoch 82/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1221 - acc: 0.9739Epoch 00081: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1222 - acc: 0.9739 - val_loss: 0.1317 - val_acc: 0.9686
Epoch 83/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1209 - acc: 0.9739Epoch 00082: val_loss improved from 0.13018 to 0.12571, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1208 - acc: 0.9740 - val_loss: 0.1257 - val_acc: 0.9715
Epoch 84/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1201 - acc: 0.9737Epoch 00083: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1200 - acc: 0.9738 - val_loss: 0.1268 - val_acc: 0.9708
Epoch 85/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1184 - acc: 0.9754Epoch 00084: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1184 - acc: 0.9754 - val_loss: 0.1310 - val_acc: 0.9681
Epoch 86/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1180 - acc: 0.9743Epoch 00085: val_loss improved from 0.12571 to 0.12398, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1178 - acc: 0.9744 - val_loss: 0.1240 - val_acc: 0.9706
Epoch 87/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.1167 - acc: 0.9751Epoch 00086: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1169 - acc: 0.9750 - val_loss: 0.1247 - val_acc: 0.9701
Epoch 88/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1156 - acc: 0.9754Epoch 00087: val_loss improved from 0.12398 to 0.11966, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1156 - acc: 0.9754 - val_loss: 0.1197 - val_acc: 0.9724
Epoch 89/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1151 - acc: 0.9756Epoch 00088: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1150 - acc: 0.9757 - val_loss: 0.1214 - val_acc: 0.9721
Epoch 90/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1132 - acc: 0.9756Epoch 00089: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1135 - acc: 0.9756 - val_loss: 0.1198 - val_acc: 0.9712
Epoch 91/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.1128 - acc: 0.9754Epoch 00090: val_loss improved from 0.11966 to 0.11788, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1130 - acc: 0.9754 - val_loss: 0.1179 - val_acc: 0.9706
Epoch 92/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1120 - acc: 0.9758Epoch 00091: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1123 - acc: 0.9759 - val_loss: 0.1180 - val_acc: 0.9719
Epoch 93/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.1116 - acc: 0.9763Epoch 00092: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1114 - acc: 0.9763 - val_loss: 0.1180 - val_acc: 0.9726
Epoch 94/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1106 - acc: 0.9760Epoch 00093: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1105 - acc: 0.9760 - val_loss: 0.1201 - val_acc: 0.9721
Epoch 95/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1098 - acc: 0.9764Epoch 00094: val_loss improved from 0.11788 to 0.11686, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1097 - acc: 0.9763 - val_loss: 0.1169 - val_acc: 0.9710
Epoch 96/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.1088 - acc: 0.9762Epoch 00095: val_loss improved from 0.11686 to 0.11596, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1087 - acc: 0.9762 - val_loss: 0.1160 - val_acc: 0.9706
Epoch 97/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1083 - acc: 0.9767Epoch 00096: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1080 - acc: 0.9768 - val_loss: 0.1173 - val_acc: 0.9710
Epoch 98/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.1074 - acc: 0.9776Epoch 00097: val_loss improved from 0.11596 to 0.11469, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1073 - acc: 0.9776 - val_loss: 0.1147 - val_acc: 0.9735
Epoch 99/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1065 - acc: 0.9773Epoch 00098: val_loss improved from 0.11469 to 0.11293, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1063 - acc: 0.9774 - val_loss: 0.1129 - val_acc: 0.9715
Epoch 100/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.1060 - acc: 0.9780Epoch 00099: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1058 - acc: 0.9781 - val_loss: 0.1137 - val_acc: 0.9719
Epoch 101/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1046 - acc: 0.9778Epoch 00100: val_loss improved from 0.11293 to 0.11097, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1050 - acc: 0.9776 - val_loss: 0.1110 - val_acc: 0.9719
Epoch 102/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.1045 - acc: 0.9772Epoch 00101: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1042 - acc: 0.9773 - val_loss: 0.1116 - val_acc: 0.9737
Epoch 103/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1036 - acc: 0.9770Epoch 00102: val_loss improved from 0.11097 to 0.10998, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1037 - acc: 0.9770 - val_loss: 0.1100 - val_acc: 0.9728
Epoch 104/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1030 - acc: 0.9780Epoch 00103: val_loss improved from 0.10998 to 0.10911, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.1030 - acc: 0.9780 - val_loss: 0.1091 - val_acc: 0.9741
Epoch 105/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.1018 - acc: 0.9783Epoch 00104: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.1019 - acc: 0.9782 - val_loss: 0.1118 - val_acc: 0.9730
Epoch 106/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.1016 - acc: 0.9771Epoch 00105: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1017 - acc: 0.9771 - val_loss: 0.1114 - val_acc: 0.9724
Epoch 107/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.1009 - acc: 0.9779Epoch 00106: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1009 - acc: 0.9779 - val_loss: 0.1095 - val_acc: 0.9719
Epoch 108/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.1007 - acc: 0.9783Epoch 00107: val_loss improved from 0.10911 to 0.10691, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.1008 - acc: 0.9783 - val_loss: 0.1069 - val_acc: 0.9721
Epoch 109/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0996 - acc: 0.9781Epoch 00108: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.1000 - acc: 0.9780 - val_loss: 0.1121 - val_acc: 0.9710
Epoch 110/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0990 - acc: 0.9784Epoch 00109: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0991 - acc: 0.9784 - val_loss: 0.1079 - val_acc: 0.9728
Epoch 111/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0987 - acc: 0.9787Epoch 00110: val_loss improved from 0.10691 to 0.10639, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0985 - acc: 0.9788 - val_loss: 0.1064 - val_acc: 0.9741
Epoch 112/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0981 - acc: 0.9788Epoch 00111: val_loss improved from 0.10639 to 0.10635, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0979 - acc: 0.9789 - val_loss: 0.1063 - val_acc: 0.9735
Epoch 113/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0975 - acc: 0.9788Epoch 00112: val_loss improved from 0.10635 to 0.10510, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0975 - acc: 0.9788 - val_loss: 0.1051 - val_acc: 0.9737
Epoch 114/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0966 - acc: 0.9788Epoch 00113: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0964 - acc: 0.9789 - val_loss: 0.1060 - val_acc: 0.9744
Epoch 115/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0962 - acc: 0.9793Epoch 00114: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0961 - acc: 0.9793 - val_loss: 0.1054 - val_acc: 0.9739
Epoch 116/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0955 - acc: 0.9790Epoch 00115: val_loss improved from 0.10510 to 0.10446, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0955 - acc: 0.9790 - val_loss: 0.1045 - val_acc: 0.9728
Epoch 117/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0951 - acc: 0.9794Epoch 00116: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0952 - acc: 0.9793 - val_loss: 0.1051 - val_acc: 0.9735
Epoch 118/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0946 - acc: 0.9793Epoch 00117: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0945 - acc: 0.9794 - val_loss: 0.1049 - val_acc: 0.9717
Epoch 119/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0942 - acc: 0.9803Epoch 00118: val_loss improved from 0.10446 to 0.10425, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0942 - acc: 0.9803 - val_loss: 0.1042 - val_acc: 0.9724
Epoch 120/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0935 - acc: 0.9795Epoch 00119: val_loss improved from 0.10425 to 0.10324, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0934 - acc: 0.9795 - val_loss: 0.1032 - val_acc: 0.9735
Epoch 121/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0935 - acc: 0.9800Epoch 00120: val_loss improved from 0.10324 to 0.10121, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0931 - acc: 0.9802 - val_loss: 0.1012 - val_acc: 0.9744
Epoch 122/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0924 - acc: 0.9798Epoch 00121: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0925 - acc: 0.9798 - val_loss: 0.1019 - val_acc: 0.9737
Epoch 123/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0917 - acc: 0.9799Epoch 00122: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0916 - acc: 0.9799 - val_loss: 0.1039 - val_acc: 0.9739
Epoch 124/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0916 - acc: 0.9803Epoch 00123: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0914 - acc: 0.9804 - val_loss: 0.1014 - val_acc: 0.9737
Epoch 125/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0909 - acc: 0.9797Epoch 00124: val_loss improved from 0.10121 to 0.09904, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0908 - acc: 0.9797 - val_loss: 0.0990 - val_acc: 0.9748
Epoch 126/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0904 - acc: 0.9799Epoch 00125: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0904 - acc: 0.9799 - val_loss: 0.0998 - val_acc: 0.9744
Epoch 127/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0897 - acc: 0.9801Epoch 00126: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0901 - acc: 0.9802 - val_loss: 0.1010 - val_acc: 0.9746
Epoch 128/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0896 - acc: 0.9797Epoch 00127: val_loss improved from 0.09904 to 0.09765, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0896 - acc: 0.9798 - val_loss: 0.0976 - val_acc: 0.9748
Epoch 129/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0889 - acc: 0.9806Epoch 00128: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0892 - acc: 0.9807 - val_loss: 0.0979 - val_acc: 0.9735
Epoch 130/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0887 - acc: 0.9805Epoch 00129: val_loss improved from 0.09765 to 0.09754, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0886 - acc: 0.9805 - val_loss: 0.0975 - val_acc: 0.9759
Epoch 131/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0885 - acc: 0.9801Epoch 00130: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0883 - acc: 0.9802 - val_loss: 0.0990 - val_acc: 0.9753
Epoch 132/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0876 - acc: 0.9809Epoch 00131: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0875 - acc: 0.9809 - val_loss: 0.1000 - val_acc: 0.9737
Epoch 133/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0872 - acc: 0.9808Epoch 00132: val_loss improved from 0.09754 to 0.09641, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0874 - acc: 0.9807 - val_loss: 0.0964 - val_acc: 0.9753
Epoch 134/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0867 - acc: 0.9806Epoch 00133: val_loss improved from 0.09641 to 0.09622, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0872 - acc: 0.9804 - val_loss: 0.0962 - val_acc: 0.9744
Epoch 135/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0864 - acc: 0.9809Epoch 00134: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0862 - acc: 0.9810 - val_loss: 0.0994 - val_acc: 0.9717
Epoch 136/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0859 - acc: 0.9813Epoch 00135: val_loss improved from 0.09622 to 0.09595, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0859 - acc: 0.9813 - val_loss: 0.0959 - val_acc: 0.9750
Epoch 137/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0856 - acc: 0.9808Epoch 00136: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0857 - acc: 0.9808 - val_loss: 0.0962 - val_acc: 0.9746
Epoch 138/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0853 - acc: 0.9811Epoch 00137: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0853 - acc: 0.9810 - val_loss: 0.0969 - val_acc: 0.9744
Epoch 139/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0847 - acc: 0.9809Epoch 00138: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0845 - acc: 0.9810 - val_loss: 0.0966 - val_acc: 0.9735
Epoch 140/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0845 - acc: 0.9811Epoch 00139: val_loss improved from 0.09595 to 0.09464, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0844 - acc: 0.9811 - val_loss: 0.0946 - val_acc: 0.9755
Epoch 141/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0842 - acc: 0.9818Epoch 00140: val_loss improved from 0.09464 to 0.09430, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0842 - acc: 0.9818 - val_loss: 0.0943 - val_acc: 0.9741
Epoch 142/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0832 - acc: 0.9818Epoch 00141: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0833 - acc: 0.9818 - val_loss: 0.0951 - val_acc: 0.9739
Epoch 143/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0834 - acc: 0.9817Epoch 00142: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0834 - acc: 0.9817 - val_loss: 0.0945 - val_acc: 0.9748
Epoch 144/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0830 - acc: 0.9815Epoch 00143: val_loss improved from 0.09430 to 0.09382, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0829 - acc: 0.9815 - val_loss: 0.0938 - val_acc: 0.9755
Epoch 145/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0826 - acc: 0.9808Epoch 00144: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0825 - acc: 0.9809 - val_loss: 0.0947 - val_acc: 0.9750
Epoch 146/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0814 - acc: 0.9814Epoch 00145: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0819 - acc: 0.9814 - val_loss: 0.0963 - val_acc: 0.9735
Epoch 147/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0819 - acc: 0.9821Epoch 00146: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0817 - acc: 0.9822 - val_loss: 0.0946 - val_acc: 0.9750
Epoch 148/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0809 - acc: 0.9812Epoch 00147: val_loss improved from 0.09382 to 0.09172, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0815 - acc: 0.9812 - val_loss: 0.0917 - val_acc: 0.9753
Epoch 149/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0807 - acc: 0.9811Epoch 00148: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0809 - acc: 0.9811 - val_loss: 0.0917 - val_acc: 0.9739
Epoch 150/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0802 - acc: 0.9815Epoch 00149: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0803 - acc: 0.9815 - val_loss: 0.0923 - val_acc: 0.9773
Epoch 151/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0805 - acc: 0.9816Epoch 00150: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0805 - acc: 0.9815 - val_loss: 0.0920 - val_acc: 0.9748
Epoch 152/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0796 - acc: 0.9821Epoch 00151: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0800 - acc: 0.9821 - val_loss: 0.0922 - val_acc: 0.9764
Epoch 153/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0794 - acc: 0.9817Epoch 00152: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0794 - acc: 0.9816 - val_loss: 0.0948 - val_acc: 0.9746
Epoch 154/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0787 - acc: 0.9821Epoch 00153: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0786 - acc: 0.9822 - val_loss: 0.0927 - val_acc: 0.9737
Epoch 155/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0791 - acc: 0.9817Epoch 00154: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0790 - acc: 0.9818 - val_loss: 0.0949 - val_acc: 0.9737
Epoch 156/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0789 - acc: 0.9821Epoch 00155: val_loss improved from 0.09172 to 0.09044, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0786 - acc: 0.9822 - val_loss: 0.0904 - val_acc: 0.9755
Epoch 157/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0787 - acc: 0.9820Epoch 00156: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0786 - acc: 0.9820 - val_loss: 0.0906 - val_acc: 0.9755
Epoch 158/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0779 - acc: 0.9824Epoch 00157: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0779 - acc: 0.9824 - val_loss: 0.0930 - val_acc: 0.9737
Epoch 159/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0775 - acc: 0.9822Epoch 00158: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0776 - acc: 0.9822 - val_loss: 0.0915 - val_acc: 0.9755
Epoch 160/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0774 - acc: 0.9826Epoch 00159: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0776 - acc: 0.9825 - val_loss: 0.0905 - val_acc: 0.9759
Epoch 161/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0769 - acc: 0.9828Epoch 00160: val_loss improved from 0.09044 to 0.08890, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0769 - acc: 0.9828 - val_loss: 0.0889 - val_acc: 0.9761
Epoch 162/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0765 - acc: 0.9828Epoch 00161: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0766 - acc: 0.9828 - val_loss: 0.0906 - val_acc: 0.9755
Epoch 163/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0764 - acc: 0.9823Epoch 00162: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0763 - acc: 0.9823 - val_loss: 0.0905 - val_acc: 0.9761
Epoch 164/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0762 - acc: 0.9831Epoch 00163: val_loss improved from 0.08890 to 0.08820, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0761 - acc: 0.9831 - val_loss: 0.0882 - val_acc: 0.9766
Epoch 165/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0764 - acc: 0.9828Epoch 00164: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0761 - acc: 0.9829 - val_loss: 0.0892 - val_acc: 0.9764
Epoch 166/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0754 - acc: 0.9825Epoch 00165: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0753 - acc: 0.9826 - val_loss: 0.0890 - val_acc: 0.9759
Epoch 167/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0757 - acc: 0.9829Epoch 00166: val_loss improved from 0.08820 to 0.08761, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0755 - acc: 0.9829 - val_loss: 0.0876 - val_acc: 0.9750
Epoch 168/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0753 - acc: 0.9824Epoch 00167: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0753 - acc: 0.9824 - val_loss: 0.0908 - val_acc: 0.9753
Epoch 169/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0751 - acc: 0.9825Epoch 00168: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0751 - acc: 0.9825 - val_loss: 0.0886 - val_acc: 0.9755
Epoch 170/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0744 - acc: 0.9834Epoch 00169: val_loss improved from 0.08761 to 0.08734, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0745 - acc: 0.9834 - val_loss: 0.0873 - val_acc: 0.9757
Epoch 171/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0745 - acc: 0.9834Epoch 00170: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0743 - acc: 0.9834 - val_loss: 0.0878 - val_acc: 0.9755
Epoch 172/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0744 - acc: 0.9833Epoch 00171: val_loss improved from 0.08734 to 0.08573, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0744 - acc: 0.9833 - val_loss: 0.0857 - val_acc: 0.9757
Epoch 173/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0738 - acc: 0.9828Epoch 00172: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0737 - acc: 0.9829 - val_loss: 0.0866 - val_acc: 0.9757
Epoch 174/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0731 - acc: 0.9837Epoch 00173: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0734 - acc: 0.9836 - val_loss: 0.0881 - val_acc: 0.9761
Epoch 175/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0730 - acc: 0.9835Epoch 00174: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0732 - acc: 0.9835 - val_loss: 0.0887 - val_acc: 0.9753
Epoch 176/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0732 - acc: 0.9837Epoch 00175: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0730 - acc: 0.9838 - val_loss: 0.0876 - val_acc: 0.9753
Epoch 177/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0726 - acc: 0.9828Epoch 00176: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0726 - acc: 0.9828 - val_loss: 0.0897 - val_acc: 0.9748
Epoch 178/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0726 - acc: 0.9836Epoch 00177: val_loss improved from 0.08573 to 0.08502, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0725 - acc: 0.9836 - val_loss: 0.0850 - val_acc: 0.9773
Epoch 179/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0716 - acc: 0.9837Epoch 00178: val_loss improved from 0.08502 to 0.08489, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0721 - acc: 0.9834 - val_loss: 0.0849 - val_acc: 0.9750
Epoch 180/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0719 - acc: 0.9834Epoch 00179: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0718 - acc: 0.9833 - val_loss: 0.0857 - val_acc: 0.9766
Epoch 181/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0713 - acc: 0.9841Epoch 00180: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0712 - acc: 0.9840 - val_loss: 0.0867 - val_acc: 0.9757
Epoch 182/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0712 - acc: 0.9841Epoch 00181: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0711 - acc: 0.9841 - val_loss: 0.0851 - val_acc: 0.9753
Epoch 183/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0707 - acc: 0.9836Epoch 00182: val_loss improved from 0.08489 to 0.08409, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0710 - acc: 0.9836 - val_loss: 0.0841 - val_acc: 0.9755
Epoch 184/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0709 - acc: 0.9836Epoch 00183: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0709 - acc: 0.9836 - val_loss: 0.0845 - val_acc: 0.9753
Epoch 185/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0707 - acc: 0.9838Epoch 00184: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0707 - acc: 0.9838 - val_loss: 0.0844 - val_acc: 0.9773
Epoch 186/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0701 - acc: 0.9841Epoch 00185: val_loss improved from 0.08409 to 0.08346, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0704 - acc: 0.9840 - val_loss: 0.0835 - val_acc: 0.9759
Epoch 187/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0702 - acc: 0.9830Epoch 00186: val_loss improved from 0.08346 to 0.08320, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0701 - acc: 0.9829 - val_loss: 0.0832 - val_acc: 0.9768
Epoch 188/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0694 - acc: 0.9837Epoch 00187: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0696 - acc: 0.9837 - val_loss: 0.0896 - val_acc: 0.9748
Epoch 189/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0696 - acc: 0.9847Epoch 00188: val_loss improved from 0.08320 to 0.08240, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0695 - acc: 0.9847 - val_loss: 0.0824 - val_acc: 0.9777
Epoch 190/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0692 - acc: 0.9842Epoch 00189: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0691 - acc: 0.9842 - val_loss: 0.0829 - val_acc: 0.9770
Epoch 191/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0693 - acc: 0.9835Epoch 00190: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0692 - acc: 0.9836 - val_loss: 0.0827 - val_acc: 0.9766
Epoch 192/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0689 - acc: 0.9846Epoch 00191: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0688 - acc: 0.9846 - val_loss: 0.0866 - val_acc: 0.9759
Epoch 193/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0690 - acc: 0.9838Epoch 00192: val_loss improved from 0.08240 to 0.08237, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0690 - acc: 0.9838 - val_loss: 0.0824 - val_acc: 0.9768
Epoch 194/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0689 - acc: 0.9843Epoch 00193: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0689 - acc: 0.9843 - val_loss: 0.0828 - val_acc: 0.9757
Epoch 195/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0683 - acc: 0.9852Epoch 00194: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0683 - acc: 0.9852 - val_loss: 0.0826 - val_acc: 0.9773
Epoch 196/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0685 - acc: 0.9837Epoch 00195: val_loss improved from 0.08237 to 0.08218, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0684 - acc: 0.9837 - val_loss: 0.0822 - val_acc: 0.9775
Epoch 197/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0679 - acc: 0.9846Epoch 00196: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0678 - acc: 0.9846 - val_loss: 0.0822 - val_acc: 0.9770
Epoch 198/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0677 - acc: 0.9845Epoch 00197: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0676 - acc: 0.9844 - val_loss: 0.0824 - val_acc: 0.9768
Epoch 199/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0674 - acc: 0.9849Epoch 00198: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0674 - acc: 0.9849 - val_loss: 0.0835 - val_acc: 0.9766
Epoch 200/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0672 - acc: 0.9842Epoch 00199: val_loss improved from 0.08218 to 0.08131, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0671 - acc: 0.9842 - val_loss: 0.0813 - val_acc: 0.9777
Epoch 201/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0673 - acc: 0.9847Epoch 00200: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0673 - acc: 0.9847 - val_loss: 0.0818 - val_acc: 0.9766
Epoch 202/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0670 - acc: 0.9845Epoch 00201: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0669 - acc: 0.9845 - val_loss: 0.0839 - val_acc: 0.9764
Epoch 203/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0669 - acc: 0.9845Epoch 00202: val_loss improved from 0.08131 to 0.08034, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0668 - acc: 0.9846 - val_loss: 0.0803 - val_acc: 0.9773
Epoch 204/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0667 - acc: 0.9849Epoch 00203: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0669 - acc: 0.9848 - val_loss: 0.0820 - val_acc: 0.9764
Epoch 205/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0663 - acc: 0.9846Epoch 00204: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0663 - acc: 0.9846 - val_loss: 0.0804 - val_acc: 0.9768
Epoch 206/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0656 - acc: 0.9845Epoch 00205: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0655 - acc: 0.9845 - val_loss: 0.0804 - val_acc: 0.9770
Epoch 207/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0659 - acc: 0.9843Epoch 00206: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0659 - acc: 0.9843 - val_loss: 0.0812 - val_acc: 0.9770
Epoch 208/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0653 - acc: 0.9853Epoch 00207: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0653 - acc: 0.9853 - val_loss: 0.0818 - val_acc: 0.9773
Epoch 209/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0657 - acc: 0.9849Epoch 00208: val_loss improved from 0.08034 to 0.07986, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0657 - acc: 0.9848 - val_loss: 0.0799 - val_acc: 0.9773
Epoch 210/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0648 - acc: 0.9852Epoch 00209: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0649 - acc: 0.9852 - val_loss: 0.0829 - val_acc: 0.9761
Epoch 211/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0649 - acc: 0.9848Epoch 00210: val_loss improved from 0.07986 to 0.07909, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0649 - acc: 0.9848 - val_loss: 0.0791 - val_acc: 0.9781
Epoch 212/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0648 - acc: 0.9848Epoch 00211: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0648 - acc: 0.9848 - val_loss: 0.0800 - val_acc: 0.9761
Epoch 213/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0648 - acc: 0.9847Epoch 00212: val_loss improved from 0.07909 to 0.07882, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0649 - acc: 0.9846 - val_loss: 0.0788 - val_acc: 0.9775
Epoch 214/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0647 - acc: 0.9854Epoch 00213: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0646 - acc: 0.9855 - val_loss: 0.0804 - val_acc: 0.9786
Epoch 215/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0643 - acc: 0.9853Epoch 00214: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0645 - acc: 0.9852 - val_loss: 0.0805 - val_acc: 0.9773
Epoch 216/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0641 - acc: 0.9854Epoch 00215: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0640 - acc: 0.9855 - val_loss: 0.0796 - val_acc: 0.9779
Epoch 217/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0642 - acc: 0.9854Epoch 00216: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0641 - acc: 0.9854 - val_loss: 0.0793 - val_acc: 0.9779
Epoch 218/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0635 - acc: 0.9858Epoch 00217: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0636 - acc: 0.9857 - val_loss: 0.0813 - val_acc: 0.9775
Epoch 219/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0638 - acc: 0.9850Epoch 00218: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0638 - acc: 0.9850 - val_loss: 0.0791 - val_acc: 0.9790
Epoch 220/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0637 - acc: 0.9851Epoch 00219: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0636 - acc: 0.9852 - val_loss: 0.0793 - val_acc: 0.9770
Epoch 221/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0635 - acc: 0.9849Epoch 00220: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0633 - acc: 0.9849 - val_loss: 0.0798 - val_acc: 0.9775
Epoch 222/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0634 - acc: 0.9856Epoch 00221: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0633 - acc: 0.9855 - val_loss: 0.0795 - val_acc: 0.9777
Epoch 223/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0627 - acc: 0.9864Epoch 00222: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0627 - acc: 0.9863 - val_loss: 0.0812 - val_acc: 0.9770
Epoch 224/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0626 - acc: 0.9856Epoch 00223: val_loss improved from 0.07882 to 0.07830, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0625 - acc: 0.9857 - val_loss: 0.0783 - val_acc: 0.9777
Epoch 225/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0622 - acc: 0.9862Epoch 00224: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0623 - acc: 0.9862 - val_loss: 0.0823 - val_acc: 0.9770
Epoch 226/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0624 - acc: 0.9857Epoch 00225: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0625 - acc: 0.9856 - val_loss: 0.0785 - val_acc: 0.9795
Epoch 227/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0620 - acc: 0.9866Epoch 00226: val_loss improved from 0.07830 to 0.07821, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0620 - acc: 0.9865 - val_loss: 0.0782 - val_acc: 0.9786
Epoch 228/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0618 - acc: 0.9857Epoch 00227: val_loss improved from 0.07821 to 0.07777, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0619 - acc: 0.9857 - val_loss: 0.0778 - val_acc: 0.9781
Epoch 229/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0619 - acc: 0.9850Epoch 00228: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0618 - acc: 0.9851 - val_loss: 0.0806 - val_acc: 0.9775
Epoch 230/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0618 - acc: 0.9859Epoch 00229: val_loss improved from 0.07777 to 0.07753, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0617 - acc: 0.9860 - val_loss: 0.0775 - val_acc: 0.9786
Epoch 231/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0615 - acc: 0.9862Epoch 00230: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0616 - acc: 0.9862 - val_loss: 0.0792 - val_acc: 0.9759
Epoch 232/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0612 - acc: 0.9863Epoch 00231: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0612 - acc: 0.9862 - val_loss: 0.0787 - val_acc: 0.9781
Epoch 233/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0612 - acc: 0.9857Epoch 00232: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0611 - acc: 0.9857 - val_loss: 0.0803 - val_acc: 0.9766
Epoch 234/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0609 - acc: 0.9862Epoch 00233: val_loss improved from 0.07753 to 0.07738, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0609 - acc: 0.9862 - val_loss: 0.0774 - val_acc: 0.9777
Epoch 235/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0609 - acc: 0.9858Epoch 00234: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0609 - acc: 0.9858 - val_loss: 0.0784 - val_acc: 0.9775
Epoch 236/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0607 - acc: 0.9861Epoch 00235: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0606 - acc: 0.9861 - val_loss: 0.0802 - val_acc: 0.9773
Epoch 237/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0607 - acc: 0.9867Epoch 00236: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0607 - acc: 0.9867 - val_loss: 0.0781 - val_acc: 0.9784
Epoch 238/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0603 - acc: 0.9861Epoch 00237: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0603 - acc: 0.9861 - val_loss: 0.0798 - val_acc: 0.9764
Epoch 239/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0601 - acc: 0.9854Epoch 00238: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0603 - acc: 0.9855 - val_loss: 0.0774 - val_acc: 0.9777
Epoch 240/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0605 - acc: 0.9855Epoch 00239: val_loss improved from 0.07738 to 0.07707, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0604 - acc: 0.9856 - val_loss: 0.0771 - val_acc: 0.9775
Epoch 241/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0603 - acc: 0.9861Epoch 00240: val_loss improved from 0.07707 to 0.07699, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0601 - acc: 0.9862 - val_loss: 0.0770 - val_acc: 0.9779
Epoch 242/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0597 - acc: 0.9858Epoch 00241: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0598 - acc: 0.9857 - val_loss: 0.0781 - val_acc: 0.9786
Epoch 243/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0600 - acc: 0.9867Epoch 00242: val_loss improved from 0.07699 to 0.07691, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0599 - acc: 0.9867 - val_loss: 0.0769 - val_acc: 0.9786
Epoch 244/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0593 - acc: 0.9859Epoch 00243: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0595 - acc: 0.9859 - val_loss: 0.0780 - val_acc: 0.9790
Epoch 245/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0592 - acc: 0.9871Epoch 00244: val_loss improved from 0.07691 to 0.07637, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0594 - acc: 0.9870 - val_loss: 0.0764 - val_acc: 0.9790
Epoch 246/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0593 - acc: 0.9861Epoch 00245: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0593 - acc: 0.9861 - val_loss: 0.0772 - val_acc: 0.9775
Epoch 247/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0587 - acc: 0.9863Epoch 00246: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0588 - acc: 0.9862 - val_loss: 0.0772 - val_acc: 0.9786
Epoch 248/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0590 - acc: 0.9865Epoch 00247: val_loss improved from 0.07637 to 0.07561, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0591 - acc: 0.9865 - val_loss: 0.0756 - val_acc: 0.9788
Epoch 249/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0585 - acc: 0.9865Epoch 00248: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0586 - acc: 0.9865 - val_loss: 0.0777 - val_acc: 0.9773
Epoch 250/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0583 - acc: 0.9866Epoch 00249: val_loss improved from 0.07561 to 0.07551, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0584 - acc: 0.9864 - val_loss: 0.0755 - val_acc: 0.9773
Epoch 251/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0585 - acc: 0.9858Epoch 00250: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0585 - acc: 0.9858 - val_loss: 0.0759 - val_acc: 0.9777
Epoch 252/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0581 - acc: 0.9868Epoch 00251: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0581 - acc: 0.9868 - val_loss: 0.0802 - val_acc: 0.9781
Epoch 253/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0583 - acc: 0.9866Epoch 00252: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0582 - acc: 0.9867 - val_loss: 0.0778 - val_acc: 0.9770
Epoch 254/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0571 - acc: 0.9870Epoch 00253: val_loss improved from 0.07551 to 0.07441, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0578 - acc: 0.9869 - val_loss: 0.0744 - val_acc: 0.9793
Epoch 255/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0574 - acc: 0.9869Epoch 00254: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0578 - acc: 0.9868 - val_loss: 0.0755 - val_acc: 0.9788
Epoch 256/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0578 - acc: 0.9871Epoch 00255: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0579 - acc: 0.9870 - val_loss: 0.0760 - val_acc: 0.9781
Epoch 257/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0579 - acc: 0.9866Epoch 00256: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0578 - acc: 0.9866 - val_loss: 0.0777 - val_acc: 0.9759
Epoch 258/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0577 - acc: 0.9869Epoch 00257: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0576 - acc: 0.9870 - val_loss: 0.0756 - val_acc: 0.9784
Epoch 259/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0576 - acc: 0.9866Epoch 00258: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0575 - acc: 0.9866 - val_loss: 0.0780 - val_acc: 0.9779
Epoch 260/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0572 - acc: 0.9866Epoch 00259: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0572 - acc: 0.9866 - val_loss: 0.0772 - val_acc: 0.9781
Epoch 261/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0569 - acc: 0.9864Epoch 00260: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0570 - acc: 0.9864 - val_loss: 0.0772 - val_acc: 0.9761
Epoch 262/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0568 - acc: 0.9872Epoch 00261: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0568 - acc: 0.9872 - val_loss: 0.0745 - val_acc: 0.9793
Epoch 263/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0567 - acc: 0.9868Epoch 00262: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0567 - acc: 0.9868 - val_loss: 0.0755 - val_acc: 0.9781
Epoch 264/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0568 - acc: 0.9870Epoch 00263: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0567 - acc: 0.9871 - val_loss: 0.0748 - val_acc: 0.9784
Epoch 265/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0569 - acc: 0.9867Epoch 00264: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0568 - acc: 0.9867 - val_loss: 0.0744 - val_acc: 0.9781
Epoch 266/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0564 - acc: 0.9867Epoch 00265: val_loss improved from 0.07441 to 0.07418, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0566 - acc: 0.9867 - val_loss: 0.0742 - val_acc: 0.9781
Epoch 267/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0564 - acc: 0.9871Epoch 00266: val_loss improved from 0.07418 to 0.07378, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0562 - acc: 0.9872 - val_loss: 0.0738 - val_acc: 0.9777
Epoch 268/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0565 - acc: 0.9869Epoch 00267: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0564 - acc: 0.9870 - val_loss: 0.0761 - val_acc: 0.9775
Epoch 269/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0560 - acc: 0.9869Epoch 00268: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0561 - acc: 0.9868 - val_loss: 0.0738 - val_acc: 0.9784
Epoch 270/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0562 - acc: 0.9864Epoch 00269: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0561 - acc: 0.9863 - val_loss: 0.0752 - val_acc: 0.9784
Epoch 271/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0556 - acc: 0.9873Epoch 00270: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0556 - acc: 0.9873 - val_loss: 0.0773 - val_acc: 0.9759
Epoch 272/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0560 - acc: 0.9872Epoch 00271: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0560 - acc: 0.9872 - val_loss: 0.0745 - val_acc: 0.9790
Epoch 273/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0556 - acc: 0.9871Epoch 00272: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0557 - acc: 0.9871 - val_loss: 0.0763 - val_acc: 0.9790
Epoch 274/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0557 - acc: 0.9874Epoch 00273: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0555 - acc: 0.9875 - val_loss: 0.0741 - val_acc: 0.9786
Epoch 275/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0554 - acc: 0.9870Epoch 00274: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0554 - acc: 0.9870 - val_loss: 0.0744 - val_acc: 0.9784
Epoch 276/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0554 - acc: 0.9878Epoch 00275: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0555 - acc: 0.9878 - val_loss: 0.0743 - val_acc: 0.9790
Epoch 277/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0550 - acc: 0.9874Epoch 00276: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0553 - acc: 0.9873 - val_loss: 0.0746 - val_acc: 0.9779
Epoch 278/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0545 - acc: 0.9875Epoch 00277: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0550 - acc: 0.9874 - val_loss: 0.0779 - val_acc: 0.9770
Epoch 279/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0549 - acc: 0.9877Epoch 00278: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0549 - acc: 0.9877 - val_loss: 0.0761 - val_acc: 0.9779
Epoch 280/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0553 - acc: 0.9873Epoch 00279: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0550 - acc: 0.9873 - val_loss: 0.0742 - val_acc: 0.9793
Epoch 281/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0548 - acc: 0.9874Epoch 00280: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0547 - acc: 0.9875 - val_loss: 0.0743 - val_acc: 0.9786
Epoch 282/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0545 - acc: 0.9875Epoch 00281: val_loss improved from 0.07378 to 0.07377, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0545 - acc: 0.9875 - val_loss: 0.0738 - val_acc: 0.9799
Epoch 283/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0545 - acc: 0.9875Epoch 00282: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0544 - acc: 0.9876 - val_loss: 0.0748 - val_acc: 0.9788
Epoch 284/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0546 - acc: 0.9874Epoch 00283: val_loss improved from 0.07377 to 0.07302, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0545 - acc: 0.9874 - val_loss: 0.0730 - val_acc: 0.9793
Epoch 285/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0539 - acc: 0.9875Epoch 00284: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0541 - acc: 0.9874 - val_loss: 0.0768 - val_acc: 0.9784
Epoch 286/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0542 - acc: 0.9873Epoch 00285: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0541 - acc: 0.9873 - val_loss: 0.0736 - val_acc: 0.9781
Epoch 287/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0538 - acc: 0.9876Epoch 00286: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0537 - acc: 0.9876 - val_loss: 0.0738 - val_acc: 0.9784
Epoch 288/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0538 - acc: 0.9874Epoch 00287: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0539 - acc: 0.9873 - val_loss: 0.0772 - val_acc: 0.9761
Epoch 289/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0540 - acc: 0.9875Epoch 00288: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0540 - acc: 0.9875 - val_loss: 0.0731 - val_acc: 0.9777
Epoch 290/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0533 - acc: 0.9878Epoch 00289: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0535 - acc: 0.9877 - val_loss: 0.0737 - val_acc: 0.9788
Epoch 291/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0533 - acc: 0.9879Epoch 00290: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0532 - acc: 0.9879 - val_loss: 0.0735 - val_acc: 0.9777
Epoch 292/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0530 - acc: 0.9878Epoch 00291: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0532 - acc: 0.9877 - val_loss: 0.0741 - val_acc: 0.9786
Epoch 293/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0534 - acc: 0.9871Epoch 00292: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0536 - acc: 0.9871 - val_loss: 0.0771 - val_acc: 0.9797
Epoch 294/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0535 - acc: 0.9876Epoch 00293: val_loss improved from 0.07302 to 0.07276, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0534 - acc: 0.9876 - val_loss: 0.0728 - val_acc: 0.9786
Epoch 295/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0533 - acc: 0.9874Epoch 00294: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0534 - acc: 0.9874 - val_loss: 0.0744 - val_acc: 0.9773
Epoch 296/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0530 - acc: 0.9877Epoch 00295: val_loss improved from 0.07276 to 0.07264, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0529 - acc: 0.9877 - val_loss: 0.0726 - val_acc: 0.9797
Epoch 297/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0531 - acc: 0.9878Epoch 00296: val_loss improved from 0.07264 to 0.07226, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0531 - acc: 0.9877 - val_loss: 0.0723 - val_acc: 0.9786
Epoch 298/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0530 - acc: 0.9878Epoch 00297: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0529 - acc: 0.9878 - val_loss: 0.0733 - val_acc: 0.9786
Epoch 299/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0528 - acc: 0.9880Epoch 00298: val_loss improved from 0.07226 to 0.07165, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0529 - acc: 0.9880 - val_loss: 0.0716 - val_acc: 0.9797
Epoch 300/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0526 - acc: 0.9879Epoch 00299: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0525 - acc: 0.9880 - val_loss: 0.0751 - val_acc: 0.9779
Epoch 301/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0525 - acc: 0.9875Epoch 00300: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0525 - acc: 0.9875 - val_loss: 0.0730 - val_acc: 0.9784
Epoch 302/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0524 - acc: 0.9881Epoch 00301: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0524 - acc: 0.9881 - val_loss: 0.0718 - val_acc: 0.9788
Epoch 303/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0523 - acc: 0.9879Epoch 00302: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0523 - acc: 0.9878 - val_loss: 0.0724 - val_acc: 0.9786
Epoch 304/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0525 - acc: 0.9878Epoch 00303: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0524 - acc: 0.9878 - val_loss: 0.0723 - val_acc: 0.9786
Epoch 305/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0523 - acc: 0.9883Epoch 00304: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0525 - acc: 0.9881 - val_loss: 0.0721 - val_acc: 0.9793
Epoch 306/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0516 - acc: 0.9877Epoch 00305: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0520 - acc: 0.9877 - val_loss: 0.0742 - val_acc: 0.9775
Epoch 307/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0518 - acc: 0.9878Epoch 00306: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0517 - acc: 0.9878 - val_loss: 0.0743 - val_acc: 0.9788
Epoch 308/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0517 - acc: 0.9883Epoch 00307: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0517 - acc: 0.9883 - val_loss: 0.0752 - val_acc: 0.9775
Epoch 309/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0518 - acc: 0.9879Epoch 00308: val_loss improved from 0.07165 to 0.07101, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0519 - acc: 0.9878 - val_loss: 0.0710 - val_acc: 0.9786
Epoch 310/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0516 - acc: 0.9879Epoch 00309: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0518 - acc: 0.9878 - val_loss: 0.0731 - val_acc: 0.9781
Epoch 311/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0516 - acc: 0.9879Epoch 00310: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0515 - acc: 0.9879 - val_loss: 0.0714 - val_acc: 0.9788
Epoch 312/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0517 - acc: 0.9881Epoch 00311: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0515 - acc: 0.9881 - val_loss: 0.0729 - val_acc: 0.9808
Epoch 313/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0516 - acc: 0.9876Epoch 00312: val_loss improved from 0.07101 to 0.07066, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0514 - acc: 0.9877 - val_loss: 0.0707 - val_acc: 0.9797
Epoch 314/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0510 - acc: 0.9881Epoch 00313: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0510 - acc: 0.9880 - val_loss: 0.0715 - val_acc: 0.9781
Epoch 315/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0517 - acc: 0.9875Epoch 00314: val_loss improved from 0.07066 to 0.07057, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0515 - acc: 0.9876 - val_loss: 0.0706 - val_acc: 0.9790
Epoch 316/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0511 - acc: 0.9885Epoch 00315: val_loss improved from 0.07057 to 0.06970, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0510 - acc: 0.9886 - val_loss: 0.0697 - val_acc: 0.9799
Epoch 317/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0510 - acc: 0.9881Epoch 00316: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0510 - acc: 0.9881 - val_loss: 0.0707 - val_acc: 0.9802
Epoch 318/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0512 - acc: 0.9883Epoch 00317: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0510 - acc: 0.9883 - val_loss: 0.0724 - val_acc: 0.9779
Epoch 319/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0506 - acc: 0.9885Epoch 00318: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0505 - acc: 0.9885 - val_loss: 0.0722 - val_acc: 0.9790
Epoch 320/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0508 - acc: 0.9888Epoch 00319: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0507 - acc: 0.9889 - val_loss: 0.0713 - val_acc: 0.9790
Epoch 321/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0509 - acc: 0.9876Epoch 00320: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0508 - acc: 0.9876 - val_loss: 0.0726 - val_acc: 0.9777
Epoch 322/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0504 - acc: 0.9883Epoch 00321: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0504 - acc: 0.9883 - val_loss: 0.0734 - val_acc: 0.9797
Epoch 323/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0495 - acc: 0.9889Epoch 00322: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0503 - acc: 0.9889 - val_loss: 0.0736 - val_acc: 0.9775
Epoch 324/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0504 - acc: 0.9885Epoch 00323: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0503 - acc: 0.9885 - val_loss: 0.0724 - val_acc: 0.9788
Epoch 325/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0505 - acc: 0.9885Epoch 00324: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0504 - acc: 0.9885 - val_loss: 0.0713 - val_acc: 0.9795
Epoch 326/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0501 - acc: 0.9889Epoch 00325: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0501 - acc: 0.9889 - val_loss: 0.0715 - val_acc: 0.9797
Epoch 327/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0500 - acc: 0.9885Epoch 00326: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0498 - acc: 0.9886 - val_loss: 0.0727 - val_acc: 0.9788
Epoch 328/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0504 - acc: 0.9883Epoch 00327: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0502 - acc: 0.9883 - val_loss: 0.0710 - val_acc: 0.9790
Epoch 329/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0494 - acc: 0.9889Epoch 00328: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0498 - acc: 0.9887 - val_loss: 0.0711 - val_acc: 0.9784
Epoch 330/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0502 - acc: 0.9885Epoch 00329: val_loss improved from 0.06970 to 0.06958, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0501 - acc: 0.9886 - val_loss: 0.0696 - val_acc: 0.9795
Epoch 331/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0499 - acc: 0.9886Epoch 00330: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0499 - acc: 0.9885 - val_loss: 0.0696 - val_acc: 0.9808
Epoch 332/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0495 - acc: 0.9888Epoch 00331: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0495 - acc: 0.9888 - val_loss: 0.0723 - val_acc: 0.9788
Epoch 333/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0495 - acc: 0.9881Epoch 00332: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0496 - acc: 0.9881 - val_loss: 0.0745 - val_acc: 0.9779
Epoch 334/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0496 - acc: 0.9883Epoch 00333: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0495 - acc: 0.9883 - val_loss: 0.0703 - val_acc: 0.9786
Epoch 335/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0495 - acc: 0.9889Epoch 00334: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0496 - acc: 0.9888 - val_loss: 0.0740 - val_acc: 0.9773
Epoch 336/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0494 - acc: 0.9886Epoch 00335: val_loss improved from 0.06958 to 0.06926, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0494 - acc: 0.9886 - val_loss: 0.0693 - val_acc: 0.9799
Epoch 337/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0492 - acc: 0.9882Epoch 00336: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0492 - acc: 0.9882 - val_loss: 0.0693 - val_acc: 0.9797
Epoch 338/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0493 - acc: 0.9885Epoch 00337: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0493 - acc: 0.9884 - val_loss: 0.0703 - val_acc: 0.9793
Epoch 339/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0482 - acc: 0.9888Epoch 00338: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0488 - acc: 0.9888 - val_loss: 0.0697 - val_acc: 0.9795
Epoch 340/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0493 - acc: 0.9890Epoch 00339: val_loss improved from 0.06926 to 0.06898, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0492 - acc: 0.9890 - val_loss: 0.0690 - val_acc: 0.9795
Epoch 341/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0490 - acc: 0.9890Epoch 00340: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0488 - acc: 0.9890 - val_loss: 0.0716 - val_acc: 0.9784
Epoch 342/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0487 - acc: 0.9886Epoch 00341: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0489 - acc: 0.9886 - val_loss: 0.0693 - val_acc: 0.9802
Epoch 343/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0487 - acc: 0.9888Epoch 00342: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0486 - acc: 0.9889 - val_loss: 0.0703 - val_acc: 0.9781
Epoch 344/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0487 - acc: 0.9891Epoch 00343: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0489 - acc: 0.9890 - val_loss: 0.0710 - val_acc: 0.9781
Epoch 345/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0486 - acc: 0.9887Epoch 00344: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0486 - acc: 0.9887 - val_loss: 0.0733 - val_acc: 0.9784
Epoch 346/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0489 - acc: 0.9891Epoch 00345: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0488 - acc: 0.9891 - val_loss: 0.0695 - val_acc: 0.9788
Epoch 347/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0482 - acc: 0.9888Epoch 00346: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0481 - acc: 0.9888 - val_loss: 0.0698 - val_acc: 0.9784
Epoch 348/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0478 - acc: 0.9891Epoch 00347: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0481 - acc: 0.9890 - val_loss: 0.0694 - val_acc: 0.9802
Epoch 349/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0486 - acc: 0.9888Epoch 00348: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0485 - acc: 0.9889 - val_loss: 0.0699 - val_acc: 0.9779
Epoch 350/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0483 - acc: 0.9887Epoch 00349: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0483 - acc: 0.9887 - val_loss: 0.0700 - val_acc: 0.9793
Epoch 351/400
17776/17939 [============================&gt;.] - ETA: 0s - loss: 0.0478 - acc: 0.9889Epoch 00350: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0479 - acc: 0.9889 - val_loss: 0.0703 - val_acc: 0.9784
Epoch 352/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0482 - acc: 0.9890Epoch 00351: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0480 - acc: 0.9890 - val_loss: 0.0707 - val_acc: 0.9788
Epoch 353/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0480 - acc: 0.9887Epoch 00352: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0479 - acc: 0.9887 - val_loss: 0.0707 - val_acc: 0.9786
Epoch 354/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0477 - acc: 0.9896Epoch 00353: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0481 - acc: 0.9895 - val_loss: 0.0698 - val_acc: 0.9790
Epoch 355/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0479 - acc: 0.9892Epoch 00354: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0477 - acc: 0.9892 - val_loss: 0.0714 - val_acc: 0.9793
Epoch 356/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0478 - acc: 0.9892Epoch 00355: val_loss improved from 0.06898 to 0.06879, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0478 - acc: 0.9892 - val_loss: 0.0688 - val_acc: 0.9802
Epoch 357/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0478 - acc: 0.9889Epoch 00356: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0476 - acc: 0.9890 - val_loss: 0.0698 - val_acc: 0.9797
Epoch 358/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0475 - acc: 0.9889Epoch 00357: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0474 - acc: 0.9890 - val_loss: 0.0696 - val_acc: 0.9799
Epoch 359/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0475 - acc: 0.9893Epoch 00358: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0474 - acc: 0.9893 - val_loss: 0.0689 - val_acc: 0.9799
Epoch 360/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0474 - acc: 0.9891Epoch 00359: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0474 - acc: 0.9891 - val_loss: 0.0736 - val_acc: 0.9770
Epoch 361/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0477 - acc: 0.9895Epoch 00360: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0477 - acc: 0.9895 - val_loss: 0.0703 - val_acc: 0.9790
Epoch 362/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0473 - acc: 0.9893Epoch 00361: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0472 - acc: 0.9893 - val_loss: 0.0703 - val_acc: 0.9790
Epoch 363/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0473 - acc: 0.9896Epoch 00362: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0473 - acc: 0.9896 - val_loss: 0.0703 - val_acc: 0.9784
Epoch 364/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0473 - acc: 0.9892Epoch 00363: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0472 - acc: 0.9892 - val_loss: 0.0728 - val_acc: 0.9786
Epoch 365/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0472 - acc: 0.9890Epoch 00364: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0473 - acc: 0.9891 - val_loss: 0.0702 - val_acc: 0.9797
Epoch 366/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0473 - acc: 0.9894Epoch 00365: val_loss improved from 0.06879 to 0.06876, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 7s - loss: 0.0472 - acc: 0.9894 - val_loss: 0.0688 - val_acc: 0.9777
Epoch 367/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0470 - acc: 0.9897Epoch 00366: val_loss improved from 0.06876 to 0.06776, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning
17939/17939 [==============================] - 6s - loss: 0.0469 - acc: 0.9897 - val_loss: 0.0678 - val_acc: 0.9806
Epoch 368/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0467 - acc: 0.9894Epoch 00367: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0467 - acc: 0.9894 - val_loss: 0.0694 - val_acc: 0.9793
Epoch 369/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0468 - acc: 0.9894Epoch 00368: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0467 - acc: 0.9895 - val_loss: 0.0683 - val_acc: 0.9802
Epoch 370/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0468 - acc: 0.9891Epoch 00369: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0470 - acc: 0.9891 - val_loss: 0.0699 - val_acc: 0.9790
Epoch 371/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0469 - acc: 0.9894Epoch 00370: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0467 - acc: 0.9894 - val_loss: 0.0737 - val_acc: 0.9788
Epoch 372/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0468 - acc: 0.9898Epoch 00371: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0467 - acc: 0.9898 - val_loss: 0.0706 - val_acc: 0.9790
Epoch 373/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0464 - acc: 0.9898Epoch 00372: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0462 - acc: 0.9898 - val_loss: 0.0692 - val_acc: 0.9790
Epoch 374/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0467 - acc: 0.9892Epoch 00373: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0466 - acc: 0.9892 - val_loss: 0.0698 - val_acc: 0.9788
Epoch 375/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0462 - acc: 0.9892Epoch 00374: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0462 - acc: 0.9892 - val_loss: 0.0689 - val_acc: 0.9793
Epoch 376/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0462 - acc: 0.9888Epoch 00375: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0463 - acc: 0.9887 - val_loss: 0.0705 - val_acc: 0.9784
Epoch 377/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0464 - acc: 0.9892Epoch 00376: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0464 - acc: 0.9892 - val_loss: 0.0683 - val_acc: 0.9808
Epoch 378/400
17824/17939 [============================&gt;.] - ETA: 0s - loss: 0.0468 - acc: 0.9892Epoch 00377: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0465 - acc: 0.9893 - val_loss: 0.0682 - val_acc: 0.9795
Epoch 379/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0461 - acc: 0.9892Epoch 00378: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0461 - acc: 0.9892 - val_loss: 0.0681 - val_acc: 0.9808
Epoch 380/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0461 - acc: 0.9893Epoch 00379: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0461 - acc: 0.9893 - val_loss: 0.0693 - val_acc: 0.9797
Epoch 381/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0457 - acc: 0.9893Epoch 00380: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0460 - acc: 0.9892 - val_loss: 0.0685 - val_acc: 0.9795
Epoch 382/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0457 - acc: 0.9898Epoch 00381: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0461 - acc: 0.9898 - val_loss: 0.0704 - val_acc: 0.9788
Epoch 383/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0459 - acc: 0.9895Epoch 00382: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0458 - acc: 0.9895 - val_loss: 0.0682 - val_acc: 0.9795
Epoch 384/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0463 - acc: 0.9896Epoch 00383: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0461 - acc: 0.9897 - val_loss: 0.0688 - val_acc: 0.9781
Epoch 385/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0459 - acc: 0.9899Epoch 00384: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0458 - acc: 0.9899 - val_loss: 0.0685 - val_acc: 0.9804
Epoch 386/400
17840/17939 [============================&gt;.] - ETA: 0s - loss: 0.0458 - acc: 0.9893Epoch 00385: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0456 - acc: 0.9894 - val_loss: 0.0687 - val_acc: 0.9797
Epoch 387/400
17888/17939 [============================&gt;.] - ETA: 0s - loss: 0.0458 - acc: 0.9896Epoch 00386: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0457 - acc: 0.9896 - val_loss: 0.0682 - val_acc: 0.9790
Epoch 388/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0458 - acc: 0.9898Epoch 00387: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0458 - acc: 0.9898 - val_loss: 0.0687 - val_acc: 0.9795
Epoch 389/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0455 - acc: 0.9895Epoch 00388: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0455 - acc: 0.9895 - val_loss: 0.0683 - val_acc: 0.9788
Epoch 390/400
17808/17939 [============================&gt;.] - ETA: 0s - loss: 0.0456 - acc: 0.9896Epoch 00389: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0454 - acc: 0.9896 - val_loss: 0.0730 - val_acc: 0.9799
Epoch 391/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0451 - acc: 0.9893Epoch 00390: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0452 - acc: 0.9892 - val_loss: 0.0714 - val_acc: 0.9790
Epoch 392/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0452 - acc: 0.9896Epoch 00391: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0452 - acc: 0.9896 - val_loss: 0.0704 - val_acc: 0.9781
Epoch 393/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0452 - acc: 0.9894Epoch 00392: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0452 - acc: 0.9894 - val_loss: 0.0689 - val_acc: 0.9786
Epoch 394/400
17856/17939 [============================&gt;.] - ETA: 0s - loss: 0.0454 - acc: 0.9898Epoch 00393: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0453 - acc: 0.9898 - val_loss: 0.0689 - val_acc: 0.9802
Epoch 395/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0451 - acc: 0.9898Epoch 00394: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0451 - acc: 0.9898 - val_loss: 0.0692 - val_acc: 0.9790
Epoch 396/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0450 - acc: 0.9897Epoch 00395: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0450 - acc: 0.9897 - val_loss: 0.0691 - val_acc: 0.9786
Epoch 397/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0452 - acc: 0.9900Epoch 00396: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0452 - acc: 0.9900 - val_loss: 0.0683 - val_acc: 0.9795
Epoch 398/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0450 - acc: 0.9899Epoch 00397: val_loss did not improve
17939/17939 [==============================] - 7s - loss: 0.0450 - acc: 0.9899 - val_loss: 0.0693 - val_acc: 0.9799
Epoch 399/400
17792/17939 [============================&gt;.] - ETA: 0s - loss: 0.0452 - acc: 0.9903Epoch 00398: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0449 - acc: 0.9904 - val_loss: 0.0688 - val_acc: 0.9793
Epoch 400/400
17872/17939 [============================&gt;.] - ETA: 0s - loss: 0.0448 - acc: 0.9895Epoch 00399: val_loss did not improve
17939/17939 [==============================] - 6s - loss: 0.0447 - acc: 0.9895 - val_loss: 0.0703 - val_acc: 0.9788
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7f7c607953c8&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_transfer_learning&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>The model is tried on the test dataset of driver images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># get index of predicted dog breed for each image in test set</span>
<span class="c1">#VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]</span>

<span class="n">VGG16_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">bottleneck_features_test_VGG16</span><span class="p">]</span>

<span class="c1"># report test accuracy</span>
<span class="c1">#test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)</span>
<span class="c1">#print(&#39;Test accuracy: %.4f%%&#39; % test_accuracy)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_subm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_files_final</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">VGG16_predictions</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kaggle-Submission---VGG16-Transfer-Learning(Model-Architecture1)">Kaggle Submission - VGG16 Transfer Learning(Model Architecture1)<a class="anchor-link" href="#Kaggle-Submission---VGG16-Transfer-Learning(Model-Architecture1)">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_submission_1.csv&#39;</span><span class="p">,</span><span class="n">VGG16_subm</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="n">comments</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">FileLink</span>
<span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_submission_1.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[28]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<a href='kaggle_submissions/VGG16_submission_1.csv' target='_blank'>kaggle_submissions/VGG16_submission_1.csv</a><br>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The submission resulted in Public Score of 1.93189. This can result in rank of 1120 out of 1440 in Public Leaderboard i.e. in top 77.77%</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Model-Architecture2">Model Architecture2<a class="anchor-link" href="#Model-Architecture2">&#182;</a></h3><p>The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We have added a Flatten layer and two fully connected layers.The last fully connected layer contains one node for each driver category and is equipped with a softmax.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">bottleneck_features_train2_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_train_VGG16.npy&#39;</span><span class="p">)</span>
<span class="n">bottleneck_features_valid2_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_valid_VGG16.npy&#39;</span><span class="p">)</span>
<span class="n">bottleneck_features_test2_VGG16</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bottleneck_features/bottleneck_features_test_VGG16.npy&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">VGG16_model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">bottleneck_features_train2_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>
<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>

<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_3 (Flatten)          (None, 25088)             0         
_________________________________________________________________
dense_5 (Dense)              (None, 500)               12544500  
_________________________________________________________________
dropout_5 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 10)                5010      
=================================================================
Total params: 12,549,510
Trainable params: 12,549,510
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_model2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-the-Model">Train the Model<a class="anchor-link" href="#Train-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_transfer_learning2&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">VGG16_model2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bottleneck_features_train2_VGG16</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">bottleneck_features_valid2_VGG16</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 17939 samples, validate on 4485 samples
Epoch 1/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 3.3116 - acc: 0.6014Epoch 00000: val_loss improved from inf to 0.07532, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 3.3054 - acc: 0.6021 - val_loss: 0.0753 - val_acc: 0.9775
Epoch 2/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.3763 - acc: 0.8923Epoch 00001: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.3769 - acc: 0.8922 - val_loss: 0.0879 - val_acc: 0.9784
Epoch 3/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2845 - acc: 0.9284Epoch 00002: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.2845 - acc: 0.9284 - val_loss: 0.1422 - val_acc: 0.9625
Epoch 4/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.2572 - acc: 0.9436Epoch 00003: val_loss improved from 0.07532 to 0.04608, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.2574 - acc: 0.9436 - val_loss: 0.0461 - val_acc: 0.9931
Epoch 5/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.2278 - acc: 0.9512Epoch 00004: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.2277 - acc: 0.9512 - val_loss: 0.0968 - val_acc: 0.9826
Epoch 6/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.2006 - acc: 0.9587Epoch 00005: val_loss improved from 0.04608 to 0.03882, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.2004 - acc: 0.9587 - val_loss: 0.0388 - val_acc: 0.9938
Epoch 7/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1971 - acc: 0.9619Epoch 00006: val_loss improved from 0.03882 to 0.03184, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1970 - acc: 0.9619 - val_loss: 0.0318 - val_acc: 0.9949
Epoch 8/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1891 - acc: 0.9653Epoch 00007: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1899 - acc: 0.9653 - val_loss: 0.0464 - val_acc: 0.9933
Epoch 9/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1777 - acc: 0.9680Epoch 00008: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1784 - acc: 0.9679 - val_loss: 0.0419 - val_acc: 0.9946
Epoch 10/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1876 - acc: 0.9701Epoch 00009: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1876 - acc: 0.9701 - val_loss: 0.0361 - val_acc: 0.9951
Epoch 11/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1634 - acc: 0.9734Epoch 00010: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1632 - acc: 0.9734 - val_loss: 0.0390 - val_acc: 0.9940
Epoch 12/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1773 - acc: 0.9727Epoch 00011: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1780 - acc: 0.9726 - val_loss: 0.0519 - val_acc: 0.9922
Epoch 13/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1562 - acc: 0.9743Epoch 00012: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1560 - acc: 0.9743 - val_loss: 0.0360 - val_acc: 0.9935
Epoch 14/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1606 - acc: 0.9739Epoch 00013: val_loss improved from 0.03184 to 0.02911, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1613 - acc: 0.9739 - val_loss: 0.0291 - val_acc: 0.9960
Epoch 15/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1652 - acc: 0.9765Epoch 00014: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1652 - acc: 0.9765 - val_loss: 0.0361 - val_acc: 0.9955
Epoch 16/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1486 - acc: 0.9774Epoch 00015: val_loss improved from 0.02911 to 0.02873, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1483 - acc: 0.9774 - val_loss: 0.0287 - val_acc: 0.9962
Epoch 17/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1602 - acc: 0.9770Epoch 00016: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1601 - acc: 0.9770 - val_loss: 0.0530 - val_acc: 0.9942
Epoch 18/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1463 - acc: 0.9784Epoch 00017: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1463 - acc: 0.9784 - val_loss: 0.0295 - val_acc: 0.9967
Epoch 19/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1478 - acc: 0.9793Epoch 00018: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1478 - acc: 0.9793 - val_loss: 0.0431 - val_acc: 0.9958
Epoch 20/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1343 - acc: 0.9809Epoch 00019: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1343 - acc: 0.9809 - val_loss: 0.0386 - val_acc: 0.9949
Epoch 21/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1495 - acc: 0.9800Epoch 00020: val_loss improved from 0.02873 to 0.02025, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1493 - acc: 0.9800 - val_loss: 0.0203 - val_acc: 0.9975
Epoch 22/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1370 - acc: 0.9816Epoch 00021: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1368 - acc: 0.9816 - val_loss: 0.0444 - val_acc: 0.9946
Epoch 23/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1318 - acc: 0.9832Epoch 00022: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1316 - acc: 0.9833 - val_loss: 0.0289 - val_acc: 0.9975
Epoch 24/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1321 - acc: 0.9837Epoch 00023: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1320 - acc: 0.9837 - val_loss: 0.0275 - val_acc: 0.9975
Epoch 25/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1429 - acc: 0.9831Epoch 00024: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1429 - acc: 0.9831 - val_loss: 0.0246 - val_acc: 0.9969
Epoch 26/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1293 - acc: 0.9837Epoch 00025: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1293 - acc: 0.9837 - val_loss: 0.0203 - val_acc: 0.9980
Epoch 27/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1382 - acc: 0.9830Epoch 00026: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1386 - acc: 0.9830 - val_loss: 0.0317 - val_acc: 0.9960
Epoch 28/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1159 - acc: 0.9857Epoch 00027: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1157 - acc: 0.9857 - val_loss: 0.0286 - val_acc: 0.9971
Epoch 29/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1265 - acc: 0.9842Epoch 00028: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1262 - acc: 0.9842 - val_loss: 0.0231 - val_acc: 0.9982
Epoch 30/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1232 - acc: 0.9858Epoch 00029: val_loss improved from 0.02025 to 0.01709, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1232 - acc: 0.9858 - val_loss: 0.0171 - val_acc: 0.9982
Epoch 31/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1265 - acc: 0.9849Epoch 00030: val_loss improved from 0.01709 to 0.01627, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1263 - acc: 0.9849 - val_loss: 0.0163 - val_acc: 0.9984
Epoch 32/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1142 - acc: 0.9861Epoch 00031: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1141 - acc: 0.9861 - val_loss: 0.0506 - val_acc: 0.9946
Epoch 33/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1073 - acc: 0.9863Epoch 00032: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1072 - acc: 0.9863 - val_loss: 0.0257 - val_acc: 0.9971
Epoch 34/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1427 - acc: 0.9851Epoch 00033: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1427 - acc: 0.9851 - val_loss: 0.0429 - val_acc: 0.9949
Epoch 35/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1138 - acc: 0.9862Epoch 00034: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1137 - acc: 0.9862 - val_loss: 0.0182 - val_acc: 0.9987
Epoch 36/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1129 - acc: 0.9878Epoch 00035: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1139 - acc: 0.9877 - val_loss: 0.0266 - val_acc: 0.9971
Epoch 37/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1457 - acc: 0.9852Epoch 00036: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1457 - acc: 0.9852 - val_loss: 0.0225 - val_acc: 0.9982
Epoch 38/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0909 - acc: 0.9892Epoch 00037: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0910 - acc: 0.9892 - val_loss: 0.0255 - val_acc: 0.9978
Epoch 39/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1042 - acc: 0.9884Epoch 00038: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1041 - acc: 0.9885 - val_loss: 0.0222 - val_acc: 0.9978
Epoch 40/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0983 - acc: 0.9883Epoch 00039: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0982 - acc: 0.9883 - val_loss: 0.0366 - val_acc: 0.9960
Epoch 41/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0988 - acc: 0.9897Epoch 00040: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0987 - acc: 0.9897 - val_loss: 0.0316 - val_acc: 0.9971
Epoch 42/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1192 - acc: 0.9878Epoch 00041: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1191 - acc: 0.9878 - val_loss: 0.0304 - val_acc: 0.9969
Epoch 43/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0911 - acc: 0.9890Epoch 00042: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0911 - acc: 0.9890 - val_loss: 0.0333 - val_acc: 0.9967
Epoch 44/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0960 - acc: 0.9882Epoch 00043: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0959 - acc: 0.9882 - val_loss: 0.0324 - val_acc: 0.9975
Epoch 45/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0987 - acc: 0.9886Epoch 00044: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0986 - acc: 0.9886 - val_loss: 0.0256 - val_acc: 0.9980
Epoch 46/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0841 - acc: 0.9895Epoch 00045: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0841 - acc: 0.9895 - val_loss: 0.0214 - val_acc: 0.9987
Epoch 47/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1024 - acc: 0.9883Epoch 00046: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1033 - acc: 0.9882 - val_loss: 0.0200 - val_acc: 0.9975
Epoch 48/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.1126 - acc: 0.9883Epoch 00047: val_loss improved from 0.01627 to 0.01460, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.1125 - acc: 0.9883 - val_loss: 0.0146 - val_acc: 0.9984
Epoch 49/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0926 - acc: 0.9895Epoch 00048: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0924 - acc: 0.9895 - val_loss: 0.0271 - val_acc: 0.9975
Epoch 50/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0851 - acc: 0.9914Epoch 00049: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0850 - acc: 0.9914 - val_loss: 0.0279 - val_acc: 0.9978
Epoch 51/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.1206 - acc: 0.9874Epoch 00050: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1203 - acc: 0.9875 - val_loss: 0.0319 - val_acc: 0.9971
Epoch 52/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1094 - acc: 0.9887Epoch 00051: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.1094 - acc: 0.9887 - val_loss: 0.0455 - val_acc: 0.9962
Epoch 53/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0942 - acc: 0.9902Epoch 00052: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0940 - acc: 0.9902 - val_loss: 0.0194 - val_acc: 0.9982
Epoch 54/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0980 - acc: 0.9893Epoch 00053: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0988 - acc: 0.9893 - val_loss: 0.0152 - val_acc: 0.9984
Epoch 55/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0801 - acc: 0.9916Epoch 00054: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0800 - acc: 0.9916 - val_loss: 0.0307 - val_acc: 0.9973
Epoch 56/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0878 - acc: 0.9905Epoch 00055: val_loss improved from 0.01460 to 0.01215, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.0878 - acc: 0.9905 - val_loss: 0.0122 - val_acc: 0.9987
Epoch 57/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0959 - acc: 0.9895Epoch 00056: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0958 - acc: 0.9895 - val_loss: 0.0189 - val_acc: 0.9973
Epoch 58/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0877 - acc: 0.9911Epoch 00057: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0876 - acc: 0.9911 - val_loss: 0.0206 - val_acc: 0.9978
Epoch 59/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0893 - acc: 0.9907Epoch 00058: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0891 - acc: 0.9907 - val_loss: 0.0250 - val_acc: 0.9978
Epoch 60/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0907 - acc: 0.9907Epoch 00059: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0906 - acc: 0.9907 - val_loss: 0.0252 - val_acc: 0.9971
Epoch 61/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0593 - acc: 0.9930Epoch 00060: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0592 - acc: 0.9930 - val_loss: 0.0200 - val_acc: 0.9975
Epoch 62/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0834 - acc: 0.9913Epoch 00061: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0834 - acc: 0.9913 - val_loss: 0.0170 - val_acc: 0.9984
Epoch 63/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0657 - acc: 0.9928Epoch 00062: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0656 - acc: 0.9928 - val_loss: 0.0137 - val_acc: 0.9982
Epoch 64/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0836 - acc: 0.9919Epoch 00063: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0836 - acc: 0.9919 - val_loss: 0.0144 - val_acc: 0.9989
Epoch 65/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0735 - acc: 0.9922Epoch 00064: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0743 - acc: 0.9922 - val_loss: 0.0249 - val_acc: 0.9982
Epoch 66/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0781 - acc: 0.9914Epoch 00065: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0789 - acc: 0.9913 - val_loss: 0.0269 - val_acc: 0.9978
Epoch 67/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0741 - acc: 0.9926Epoch 00066: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0740 - acc: 0.9926 - val_loss: 0.0278 - val_acc: 0.9975
Epoch 68/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0972 - acc: 0.9902Epoch 00067: val_loss improved from 0.01215 to 0.00922, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.0970 - acc: 0.9902 - val_loss: 0.0092 - val_acc: 0.9989
Epoch 69/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0720 - acc: 0.9921Epoch 00068: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0720 - acc: 0.9921 - val_loss: 0.0192 - val_acc: 0.9982
Epoch 70/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0785 - acc: 0.9917Epoch 00069: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0785 - acc: 0.9917 - val_loss: 0.0223 - val_acc: 0.9980
Epoch 71/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0780 - acc: 0.9921Epoch 00070: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0780 - acc: 0.9921 - val_loss: 0.0329 - val_acc: 0.9971
Epoch 72/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0740 - acc: 0.9919Epoch 00071: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0739 - acc: 0.9919 - val_loss: 0.0210 - val_acc: 0.9984
Epoch 73/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0805 - acc: 0.9919Epoch 00072: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0804 - acc: 0.9919 - val_loss: 0.0216 - val_acc: 0.9984
Epoch 74/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0859 - acc: 0.9913Epoch 00073: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0857 - acc: 0.9914 - val_loss: 0.0158 - val_acc: 0.9984
Epoch 75/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0816 - acc: 0.9912Epoch 00074: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0816 - acc: 0.9912 - val_loss: 0.0222 - val_acc: 0.9982
Epoch 76/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0735 - acc: 0.9921Epoch 00075: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0734 - acc: 0.9921 - val_loss: 0.0258 - val_acc: 0.9978
Epoch 77/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0723 - acc: 0.9916Epoch 00076: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0721 - acc: 0.9916 - val_loss: 0.0217 - val_acc: 0.9982
Epoch 78/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0734 - acc: 0.9923Epoch 00077: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0733 - acc: 0.9923 - val_loss: 0.0142 - val_acc: 0.9982
Epoch 79/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0908 - acc: 0.9914Epoch 00078: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0907 - acc: 0.9913 - val_loss: 0.0236 - val_acc: 0.9980
Epoch 80/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0601 - acc: 0.9931Epoch 00079: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0601 - acc: 0.9931 - val_loss: 0.0174 - val_acc: 0.9982
Epoch 81/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0446 - acc: 0.9951Epoch 00080: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0446 - acc: 0.9952 - val_loss: 0.0226 - val_acc: 0.9982
Epoch 82/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0798 - acc: 0.9915Epoch 00081: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0798 - acc: 0.9915 - val_loss: 0.0144 - val_acc: 0.9989
Epoch 83/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0617 - acc: 0.9936Epoch 00082: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0617 - acc: 0.9936 - val_loss: 0.0388 - val_acc: 0.9967
Epoch 84/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0632 - acc: 0.9931Epoch 00083: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0631 - acc: 0.9931 - val_loss: 0.0385 - val_acc: 0.9969
Epoch 85/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0921 - acc: 0.9912Epoch 00084: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0919 - acc: 0.9912 - val_loss: 0.0201 - val_acc: 0.9987
Epoch 86/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0648 - acc: 0.9934Epoch 00085: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0646 - acc: 0.9934 - val_loss: 0.0313 - val_acc: 0.9971
Epoch 87/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0738 - acc: 0.9927Epoch 00086: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0737 - acc: 0.9927 - val_loss: 0.0167 - val_acc: 0.9987
Epoch 88/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0587 - acc: 0.9941Epoch 00087: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0586 - acc: 0.9941 - val_loss: 0.0162 - val_acc: 0.9987
Epoch 89/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0491 - acc: 0.9939Epoch 00088: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0491 - acc: 0.9939 - val_loss: 0.0181 - val_acc: 0.9984
Epoch 90/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0661 - acc: 0.9933Epoch 00089: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0661 - acc: 0.9933 - val_loss: 0.0268 - val_acc: 0.9973
Epoch 91/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0645 - acc: 0.9934Epoch 00090: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0644 - acc: 0.9934 - val_loss: 0.0215 - val_acc: 0.9982
Epoch 92/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0606 - acc: 0.9934Epoch 00091: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0605 - acc: 0.9934 - val_loss: 0.0185 - val_acc: 0.9984
Epoch 93/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0585 - acc: 0.9938Epoch 00092: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0584 - acc: 0.9938 - val_loss: 0.0296 - val_acc: 0.9971
Epoch 94/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0573 - acc: 0.9938Epoch 00093: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0573 - acc: 0.9938 - val_loss: 0.0243 - val_acc: 0.9978
Epoch 95/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0699 - acc: 0.9927Epoch 00094: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0698 - acc: 0.9928 - val_loss: 0.0240 - val_acc: 0.9980
Epoch 96/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0515 - acc: 0.9938Epoch 00095: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0524 - acc: 0.9938 - val_loss: 0.0298 - val_acc: 0.9973
Epoch 97/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0751 - acc: 0.9931Epoch 00096: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0750 - acc: 0.9931 - val_loss: 0.0189 - val_acc: 0.9984
Epoch 98/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0592 - acc: 0.9932Epoch 00097: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0591 - acc: 0.9932 - val_loss: 0.0220 - val_acc: 0.9984
Epoch 99/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0576 - acc: 0.9942Epoch 00098: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0575 - acc: 0.9942 - val_loss: 0.0098 - val_acc: 0.9991
Epoch 100/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0562 - acc: 0.9939Epoch 00099: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0562 - acc: 0.9939 - val_loss: 0.0299 - val_acc: 0.9973
Epoch 101/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0742 - acc: 0.9929Epoch 00100: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0740 - acc: 0.9929 - val_loss: 0.0262 - val_acc: 0.9971
Epoch 102/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0480 - acc: 0.9951Epoch 00101: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0480 - acc: 0.9951 - val_loss: 0.0205 - val_acc: 0.9978
Epoch 103/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0555 - acc: 0.9944Epoch 00102: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0563 - acc: 0.9943 - val_loss: 0.0216 - val_acc: 0.9980
Epoch 104/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0381 - acc: 0.9963Epoch 00103: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0381 - acc: 0.9963 - val_loss: 0.0216 - val_acc: 0.9987
Epoch 105/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0506 - acc: 0.9949Epoch 00104: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0505 - acc: 0.9949 - val_loss: 0.0230 - val_acc: 0.9978
Epoch 106/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0652 - acc: 0.9938Epoch 00105: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0651 - acc: 0.9938 - val_loss: 0.0308 - val_acc: 0.9975
Epoch 107/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0516 - acc: 0.9945Epoch 00106: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0516 - acc: 0.9945 - val_loss: 0.0272 - val_acc: 0.9975
Epoch 108/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0442 - acc: 0.9956Epoch 00107: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0441 - acc: 0.9957 - val_loss: 0.0215 - val_acc: 0.9982
Epoch 109/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0440 - acc: 0.9948Epoch 00108: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0440 - acc: 0.9948 - val_loss: 0.0174 - val_acc: 0.9982
Epoch 110/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0566 - acc: 0.9949Epoch 00109: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0565 - acc: 0.9949 - val_loss: 0.0332 - val_acc: 0.9973
Epoch 111/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0440 - acc: 0.9954Epoch 00110: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0439 - acc: 0.9954 - val_loss: 0.0185 - val_acc: 0.9984
Epoch 112/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0509 - acc: 0.9945Epoch 00111: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0509 - acc: 0.9945 - val_loss: 0.0140 - val_acc: 0.9984
Epoch 113/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0612 - acc: 0.9941Epoch 00112: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0611 - acc: 0.9941 - val_loss: 0.0155 - val_acc: 0.9989
Epoch 114/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0694 - acc: 0.9931Epoch 00113: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0694 - acc: 0.9931 - val_loss: 0.0279 - val_acc: 0.9980
Epoch 115/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0711 - acc: 0.9929Epoch 00114: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0711 - acc: 0.9929 - val_loss: 0.0232 - val_acc: 0.9980
Epoch 116/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0566 - acc: 0.9949Epoch 00115: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0566 - acc: 0.9949 - val_loss: 0.0321 - val_acc: 0.9973
Epoch 117/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0646 - acc: 0.9936Epoch 00116: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0645 - acc: 0.9936 - val_loss: 0.0217 - val_acc: 0.9982
Epoch 118/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0549 - acc: 0.9943Epoch 00117: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0549 - acc: 0.9943 - val_loss: 0.0166 - val_acc: 0.9984
Epoch 119/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0395 - acc: 0.9955Epoch 00118: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0395 - acc: 0.9955 - val_loss: 0.0102 - val_acc: 0.9991
Epoch 120/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0564 - acc: 0.9945Epoch 00119: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0564 - acc: 0.9945 - val_loss: 0.0098 - val_acc: 0.9991
Epoch 121/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0621 - acc: 0.9941Epoch 00120: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0620 - acc: 0.9941 - val_loss: 0.0216 - val_acc: 0.9982
Epoch 122/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0670 - acc: 0.9934Epoch 00121: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0669 - acc: 0.9934 - val_loss: 0.0233 - val_acc: 0.9978
Epoch 123/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0565 - acc: 0.9943Epoch 00122: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0564 - acc: 0.9943 - val_loss: 0.0195 - val_acc: 0.9984
Epoch 124/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0384 - acc: 0.9955Epoch 00123: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0384 - acc: 0.9955 - val_loss: 0.0171 - val_acc: 0.9984
Epoch 125/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0498 - acc: 0.9944Epoch 00124: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0501 - acc: 0.9943 - val_loss: 0.0270 - val_acc: 0.9973
Epoch 126/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0568 - acc: 0.9945Epoch 00125: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0567 - acc: 0.9945 - val_loss: 0.0183 - val_acc: 0.9975
Epoch 127/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0445 - acc: 0.9949Epoch 00126: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0445 - acc: 0.9949 - val_loss: 0.0193 - val_acc: 0.9984
Epoch 128/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0514 - acc: 0.9951Epoch 00127: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0514 - acc: 0.9951 - val_loss: 0.0197 - val_acc: 0.9984
Epoch 129/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0549 - acc: 0.9944Epoch 00128: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0549 - acc: 0.9944 - val_loss: 0.0102 - val_acc: 0.9991
Epoch 130/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0341 - acc: 0.9962Epoch 00129: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0340 - acc: 0.9962 - val_loss: 0.0172 - val_acc: 0.9984
Epoch 131/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0529 - acc: 0.9943Epoch 00130: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0529 - acc: 0.9943 - val_loss: 0.0261 - val_acc: 0.9982
Epoch 132/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0617 - acc: 0.9945Epoch 00131: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0616 - acc: 0.9945 - val_loss: 0.0127 - val_acc: 0.9991
Epoch 133/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0395 - acc: 0.9954Epoch 00132: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0395 - acc: 0.9954 - val_loss: 0.0165 - val_acc: 0.9984
Epoch 134/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0452 - acc: 0.9957Epoch 00133: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0452 - acc: 0.9957 - val_loss: 0.0119 - val_acc: 0.9991
Epoch 135/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0455 - acc: 0.9953Epoch 00134: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0455 - acc: 0.9953 - val_loss: 0.0152 - val_acc: 0.9987
Epoch 136/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0391 - acc: 0.9961Epoch 00135: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0393 - acc: 0.9960 - val_loss: 0.0228 - val_acc: 0.9984
Epoch 137/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0350 - acc: 0.9969Epoch 00136: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0350 - acc: 0.9969 - val_loss: 0.0163 - val_acc: 0.9987
Epoch 138/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0398 - acc: 0.9961Epoch 00137: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0397 - acc: 0.9961 - val_loss: 0.0277 - val_acc: 0.9978
Epoch 139/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0502 - acc: 0.9949Epoch 00138: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0501 - acc: 0.9949 - val_loss: 0.0189 - val_acc: 0.9984
Epoch 140/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0398 - acc: 0.9960Epoch 00139: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0398 - acc: 0.9960 - val_loss: 0.0151 - val_acc: 0.9989
Epoch 141/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0459 - acc: 0.9954Epoch 00140: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0458 - acc: 0.9954 - val_loss: 0.0319 - val_acc: 0.9978
Epoch 142/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0336 - acc: 0.9965Epoch 00141: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0335 - acc: 0.9965 - val_loss: 0.0324 - val_acc: 0.9973
Epoch 143/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0307 - acc: 0.9968Epoch 00142: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0306 - acc: 0.9968 - val_loss: 0.0150 - val_acc: 0.9987
Epoch 144/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0448 - acc: 0.9959Epoch 00143: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0447 - acc: 0.9959 - val_loss: 0.0249 - val_acc: 0.9984
Epoch 145/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0378 - acc: 0.9961Epoch 00144: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0378 - acc: 0.9961 - val_loss: 0.0102 - val_acc: 0.9989
Epoch 146/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0275 - acc: 0.9969Epoch 00145: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0274 - acc: 0.9969 - val_loss: 0.0211 - val_acc: 0.9987
Epoch 147/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0478 - acc: 0.9951Epoch 00146: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0478 - acc: 0.9952 - val_loss: 0.0263 - val_acc: 0.9982
Epoch 148/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0372 - acc: 0.9964Epoch 00147: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0372 - acc: 0.9964 - val_loss: 0.0178 - val_acc: 0.9984
Epoch 149/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0544 - acc: 0.9950Epoch 00148: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0543 - acc: 0.9950 - val_loss: 0.0194 - val_acc: 0.9982
Epoch 150/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0461 - acc: 0.9950Epoch 00149: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0460 - acc: 0.9950 - val_loss: 0.0235 - val_acc: 0.9978
Epoch 151/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0424 - acc: 0.9955Epoch 00150: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0424 - acc: 0.9955 - val_loss: 0.0143 - val_acc: 0.9989
Epoch 152/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0468 - acc: 0.9950Epoch 00151: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0467 - acc: 0.9950 - val_loss: 0.0191 - val_acc: 0.9982
Epoch 153/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0234 - acc: 0.9973Epoch 00152: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0243 - acc: 0.9972 - val_loss: 0.0321 - val_acc: 0.9975
Epoch 154/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0580 - acc: 0.9947Epoch 00153: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0579 - acc: 0.9947 - val_loss: 0.0243 - val_acc: 0.9980
Epoch 155/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0453 - acc: 0.9953Epoch 00154: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0453 - acc: 0.9953 - val_loss: 0.0210 - val_acc: 0.9978
Epoch 156/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0411 - acc: 0.9956Epoch 00155: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0410 - acc: 0.9956 - val_loss: 0.0150 - val_acc: 0.9989
Epoch 157/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0400 - acc: 0.9961Epoch 00156: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0400 - acc: 0.9961 - val_loss: 0.0202 - val_acc: 0.9982
Epoch 158/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0480 - acc: 0.9951Epoch 00157: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0479 - acc: 0.9952 - val_loss: 0.0242 - val_acc: 0.9982
Epoch 159/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0412 - acc: 0.9953Epoch 00158: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0412 - acc: 0.9953 - val_loss: 0.0188 - val_acc: 0.9984
Epoch 160/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0507 - acc: 0.9948Epoch 00159: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0507 - acc: 0.9948 - val_loss: 0.0229 - val_acc: 0.9978
Epoch 161/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0388 - acc: 0.9964Epoch 00160: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0388 - acc: 0.9964 - val_loss: 0.0191 - val_acc: 0.9984
Epoch 162/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0421 - acc: 0.9958Epoch 00161: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0421 - acc: 0.9958 - val_loss: 0.0171 - val_acc: 0.9987
Epoch 163/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0532 - acc: 0.9949Epoch 00162: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0532 - acc: 0.9949 - val_loss: 0.0168 - val_acc: 0.9984
Epoch 164/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0523 - acc: 0.9953Epoch 00163: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0522 - acc: 0.9953 - val_loss: 0.0129 - val_acc: 0.9987
Epoch 165/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0389 - acc: 0.9954Epoch 00164: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0389 - acc: 0.9954 - val_loss: 0.0197 - val_acc: 0.9978
Epoch 166/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0389 - acc: 0.9957Epoch 00165: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0389 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9984
Epoch 167/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0401 - acc: 0.9961Epoch 00166: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0401 - acc: 0.9961 - val_loss: 0.0177 - val_acc: 0.9987
Epoch 168/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0476 - acc: 0.9951Epoch 00167: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0475 - acc: 0.9952 - val_loss: 0.0147 - val_acc: 0.9987
Epoch 169/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0277 - acc: 0.9972Epoch 00168: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0277 - acc: 0.9972 - val_loss: 0.0249 - val_acc: 0.9982
Epoch 170/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0354 - acc: 0.9963Epoch 00169: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0355 - acc: 0.9963 - val_loss: 0.0205 - val_acc: 0.9987
Epoch 171/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0385 - acc: 0.9959Epoch 00170: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0385 - acc: 0.9959 - val_loss: 0.0136 - val_acc: 0.9989
Epoch 172/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0406 - acc: 0.9958Epoch 00171: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0405 - acc: 0.9958 - val_loss: 0.0204 - val_acc: 0.9980
Epoch 173/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0277 - acc: 0.9970Epoch 00172: val_loss improved from 0.00922 to 0.00756, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.0276 - acc: 0.9970 - val_loss: 0.0076 - val_acc: 0.9993
Epoch 174/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0203 - acc: 0.9975Epoch 00173: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0203 - acc: 0.9975 - val_loss: 0.0161 - val_acc: 0.9989
Epoch 175/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0231 - acc: 0.9971Epoch 00174: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0230 - acc: 0.9971 - val_loss: 0.0158 - val_acc: 0.9987
Epoch 176/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0372 - acc: 0.9964Epoch 00175: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0372 - acc: 0.9964 - val_loss: 0.0282 - val_acc: 0.9975
Epoch 177/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0653 - acc: 0.9940Epoch 00176: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0662 - acc: 0.9939 - val_loss: 0.0234 - val_acc: 0.9980
Epoch 178/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0596 - acc: 0.9946Epoch 00177: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0594 - acc: 0.9946 - val_loss: 0.0201 - val_acc: 0.9984
Epoch 179/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0311 - acc: 0.9964Epoch 00178: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0311 - acc: 0.9964 - val_loss: 0.0192 - val_acc: 0.9987
Epoch 180/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0370 - acc: 0.9962Epoch 00179: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0369 - acc: 0.9962 - val_loss: 0.0171 - val_acc: 0.9989
Epoch 181/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0250 - acc: 0.9970Epoch 00180: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0250 - acc: 0.9970 - val_loss: 0.0196 - val_acc: 0.9984
Epoch 182/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0303 - acc: 0.9969Epoch 00181: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0302 - acc: 0.9969 - val_loss: 0.0202 - val_acc: 0.9984
Epoch 183/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0181 - acc: 0.9979Epoch 00182: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0181 - acc: 0.9979 - val_loss: 0.0190 - val_acc: 0.9982
Epoch 184/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0266 - acc: 0.9971Epoch 00183: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0265 - acc: 0.9971 - val_loss: 0.0187 - val_acc: 0.9982
Epoch 185/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0251 - acc: 0.9975Epoch 00184: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0251 - acc: 0.9975 - val_loss: 0.0200 - val_acc: 0.9980
Epoch 186/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0290 - acc: 0.9973Epoch 00185: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0290 - acc: 0.9973 - val_loss: 0.0205 - val_acc: 0.9984
Epoch 187/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0305 - acc: 0.9968Epoch 00186: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0304 - acc: 0.9968 - val_loss: 0.0148 - val_acc: 0.9989
Epoch 188/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0314 - acc: 0.9969Epoch 00187: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0314 - acc: 0.9969 - val_loss: 0.0151 - val_acc: 0.9989
Epoch 189/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0286 - acc: 0.9972Epoch 00188: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0289 - acc: 0.9971 - val_loss: 0.0205 - val_acc: 0.9982
Epoch 190/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0358 - acc: 0.9964Epoch 00189: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0358 - acc: 0.9964 - val_loss: 0.0282 - val_acc: 0.9975
Epoch 191/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0252 - acc: 0.9971Epoch 00190: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0261 - acc: 0.9970 - val_loss: 0.0276 - val_acc: 0.9975
Epoch 192/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0378 - acc: 0.9961Epoch 00191: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0378 - acc: 0.9961 - val_loss: 0.0149 - val_acc: 0.9989
Epoch 193/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0383 - acc: 0.9964Epoch 00192: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0383 - acc: 0.9964 - val_loss: 0.0235 - val_acc: 0.9984
Epoch 194/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0300 - acc: 0.9971Epoch 00193: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0300 - acc: 0.9971 - val_loss: 0.0099 - val_acc: 0.9993
Epoch 195/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0162 - acc: 0.9982Epoch 00194: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0162 - acc: 0.9982 - val_loss: 0.0218 - val_acc: 0.9984
Epoch 196/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0278 - acc: 0.9972Epoch 00195: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0278 - acc: 0.9972 - val_loss: 0.0150 - val_acc: 0.9989
Epoch 197/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0387 - acc: 0.9963Epoch 00196: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0387 - acc: 0.9963 - val_loss: 0.0149 - val_acc: 0.9984
Epoch 198/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0470 - acc: 0.9956Epoch 00197: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0470 - acc: 0.9956 - val_loss: 0.0218 - val_acc: 0.9982
Epoch 199/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0447 - acc: 0.9957Epoch 00198: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0447 - acc: 0.9957 - val_loss: 0.0180 - val_acc: 0.9989
Epoch 200/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0349 - acc: 0.9965Epoch 00199: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0348 - acc: 0.9965 - val_loss: 0.0115 - val_acc: 0.9987
Epoch 201/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0294 - acc: 0.9972Epoch 00200: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0293 - acc: 0.9972 - val_loss: 0.0232 - val_acc: 0.9984
Epoch 202/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0222 - acc: 0.9975Epoch 00201: val_loss improved from 0.00756 to 0.00749, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.0222 - acc: 0.9975 - val_loss: 0.0075 - val_acc: 0.9993
Epoch 203/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0226 - acc: 0.9974Epoch 00202: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0178 - val_acc: 0.9989
Epoch 204/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0321 - acc: 0.9969Epoch 00203: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0321 - acc: 0.9969 - val_loss: 0.0144 - val_acc: 0.9987
Epoch 205/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0389 - acc: 0.9961Epoch 00204: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0389 - acc: 0.9962 - val_loss: 0.0109 - val_acc: 0.9989
Epoch 206/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0330 - acc: 0.9968Epoch 00205: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0330 - acc: 0.9968 - val_loss: 0.0226 - val_acc: 0.9984
Epoch 207/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0336 - acc: 0.9965Epoch 00206: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0336 - acc: 0.9965 - val_loss: 0.0117 - val_acc: 0.9989
Epoch 208/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0385 - acc: 0.9961Epoch 00207: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0385 - acc: 0.9962 - val_loss: 0.0089 - val_acc: 0.9993
Epoch 209/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0411 - acc: 0.9966Epoch 00208: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0410 - acc: 0.9967 - val_loss: 0.0169 - val_acc: 0.9987
Epoch 210/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0343 - acc: 0.9967Epoch 00209: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0343 - acc: 0.9967 - val_loss: 0.0387 - val_acc: 0.9973
Epoch 211/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0290 - acc: 0.9975Epoch 00210: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0289 - acc: 0.9975 - val_loss: 0.0272 - val_acc: 0.9978
Epoch 212/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0361 - acc: 0.9965Epoch 00211: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0360 - acc: 0.9965 - val_loss: 0.0151 - val_acc: 0.9987
Epoch 213/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0227 - acc: 0.9973Epoch 00212: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0227 - acc: 0.9973 - val_loss: 0.0141 - val_acc: 0.9987
Epoch 214/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0296 - acc: 0.9973Epoch 00213: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0295 - acc: 0.9973 - val_loss: 0.0152 - val_acc: 0.9984
Epoch 215/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0238 - acc: 0.9975Epoch 00214: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0238 - acc: 0.9975 - val_loss: 0.0108 - val_acc: 0.9991
Epoch 216/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0278 - acc: 0.9973Epoch 00215: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0283 - acc: 0.9972 - val_loss: 0.0385 - val_acc: 0.9973
Epoch 217/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0302 - acc: 0.9968Epoch 00216: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0302 - acc: 0.9968 - val_loss: 0.0138 - val_acc: 0.9989
Epoch 218/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0429 - acc: 0.9962Epoch 00217: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0428 - acc: 0.9962 - val_loss: 0.0187 - val_acc: 0.9984
Epoch 219/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0400 - acc: 0.9963Epoch 00218: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0400 - acc: 0.9963 - val_loss: 0.0267 - val_acc: 0.9978
Epoch 220/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0186 - acc: 0.9980Epoch 00219: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0186 - acc: 0.9980 - val_loss: 0.0097 - val_acc: 0.9993
Epoch 221/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0369 - acc: 0.9963Epoch 00220: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0369 - acc: 0.9963 - val_loss: 0.0172 - val_acc: 0.9987
Epoch 222/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0313 - acc: 0.9968Epoch 00221: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0312 - acc: 0.9968 - val_loss: 0.0140 - val_acc: 0.9987
Epoch 223/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0257 - acc: 0.9972Epoch 00222: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0257 - acc: 0.9972 - val_loss: 0.0171 - val_acc: 0.9989
Epoch 224/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0285 - acc: 0.9971Epoch 00223: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0294 - acc: 0.9970 - val_loss: 0.0108 - val_acc: 0.9993
Epoch 225/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0306 - acc: 0.9970Epoch 00224: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0306 - acc: 0.9970 - val_loss: 0.0116 - val_acc: 0.9989
Epoch 226/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0260 - acc: 0.9972Epoch 00225: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0260 - acc: 0.9972 - val_loss: 0.0163 - val_acc: 0.9984
Epoch 227/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0231 - acc: 0.9974Epoch 00226: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0231 - acc: 0.9974 - val_loss: 0.0114 - val_acc: 0.9989
Epoch 228/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0312 - acc: 0.9972Epoch 00227: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0311 - acc: 0.9972 - val_loss: 0.0186 - val_acc: 0.9987
Epoch 229/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0192 - acc: 0.9977Epoch 00228: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0192 - acc: 0.9977 - val_loss: 0.0247 - val_acc: 0.9980
Epoch 230/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0308 - acc: 0.9972Epoch 00229: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0308 - acc: 0.9972 - val_loss: 0.0108 - val_acc: 0.9993
Epoch 231/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0254 - acc: 0.9972Epoch 00230: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0253 - acc: 0.9972 - val_loss: 0.0213 - val_acc: 0.9984
Epoch 232/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0259 - acc: 0.9971Epoch 00231: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0258 - acc: 0.9971 - val_loss: 0.0178 - val_acc: 0.9984
Epoch 233/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0347 - acc: 0.9968Epoch 00232: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0346 - acc: 0.9968 - val_loss: 0.0192 - val_acc: 0.9984
Epoch 234/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0292 - acc: 0.9965Epoch 00233: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0291 - acc: 0.9965 - val_loss: 0.0129 - val_acc: 0.9989
Epoch 235/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0168 - acc: 0.9983Epoch 00234: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0168 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9984
Epoch 236/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0286 - acc: 0.9969Epoch 00235: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0286 - acc: 0.9969 - val_loss: 0.0118 - val_acc: 0.9991
Epoch 237/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0299 - acc: 0.9968Epoch 00236: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0299 - acc: 0.9968 - val_loss: 0.0113 - val_acc: 0.9989
Epoch 238/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0227 - acc: 0.9977Epoch 00237: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0226 - acc: 0.9977 - val_loss: 0.0199 - val_acc: 0.9982
Epoch 239/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0428 - acc: 0.9959Epoch 00238: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0427 - acc: 0.9959 - val_loss: 0.0132 - val_acc: 0.9989
Epoch 240/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0270 - acc: 0.9972Epoch 00239: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0269 - acc: 0.9972 - val_loss: 0.0213 - val_acc: 0.9984
Epoch 241/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0221 - acc: 0.9973Epoch 00240: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0221 - acc: 0.9973 - val_loss: 0.0182 - val_acc: 0.9984
Epoch 242/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0229 - acc: 0.9973Epoch 00241: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0229 - acc: 0.9973 - val_loss: 0.0264 - val_acc: 0.9982
Epoch 243/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0277 - acc: 0.9971Epoch 00242: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0277 - acc: 0.9971 - val_loss: 0.0164 - val_acc: 0.9984
Epoch 244/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0300 - acc: 0.9970Epoch 00243: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0300 - acc: 0.9970 - val_loss: 0.0235 - val_acc: 0.9984
Epoch 245/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0210 - acc: 0.9976Epoch 00244: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0210 - acc: 0.9976 - val_loss: 0.0155 - val_acc: 0.9987
Epoch 246/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0200 - acc: 0.9977Epoch 00245: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0200 - acc: 0.9977 - val_loss: 0.0134 - val_acc: 0.9991
Epoch 247/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0257 - acc: 0.9970Epoch 00246: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0257 - acc: 0.9970 - val_loss: 0.0165 - val_acc: 0.9987
Epoch 248/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0273 - acc: 0.9973Epoch 00247: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0273 - acc: 0.9973 - val_loss: 0.0220 - val_acc: 0.9982
Epoch 249/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0275 - acc: 0.9973Epoch 00248: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0274 - acc: 0.9973 - val_loss: 0.0200 - val_acc: 0.9987
Epoch 250/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0257 - acc: 0.9972Epoch 00249: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0257 - acc: 0.9972 - val_loss: 0.0243 - val_acc: 0.9982
Epoch 251/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0318 - acc: 0.9964Epoch 00250: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0318 - acc: 0.9964 - val_loss: 0.0104 - val_acc: 0.9989
Epoch 252/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0190 - acc: 0.9977Epoch 00251: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0190 - acc: 0.9977 - val_loss: 0.0206 - val_acc: 0.9982
Epoch 253/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0311 - acc: 0.9968Epoch 00252: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0311 - acc: 0.9968 - val_loss: 0.0114 - val_acc: 0.9989
Epoch 254/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0199 - acc: 0.9981Epoch 00253: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0199 - acc: 0.9981 - val_loss: 0.0187 - val_acc: 0.9984
Epoch 255/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0257 - acc: 0.9974Epoch 00254: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0257 - acc: 0.9974 - val_loss: 0.0109 - val_acc: 0.9991
Epoch 256/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0284 - acc: 0.9967Epoch 00255: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0284 - acc: 0.9967 - val_loss: 0.0145 - val_acc: 0.9987
Epoch 257/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0282 - acc: 0.9973Epoch 00256: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0282 - acc: 0.9973 - val_loss: 0.0238 - val_acc: 0.9984
Epoch 258/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0334 - acc: 0.9968Epoch 00257: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0334 - acc: 0.9968 - val_loss: 0.0120 - val_acc: 0.9991
Epoch 259/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0201 - acc: 0.9975Epoch 00258: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0201 - acc: 0.9975 - val_loss: 0.0196 - val_acc: 0.9987
Epoch 260/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0282 - acc: 0.9974Epoch 00259: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0281 - acc: 0.9974 - val_loss: 0.0208 - val_acc: 0.9984
Epoch 261/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0237 - acc: 0.9975Epoch 00260: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0237 - acc: 0.9975 - val_loss: 0.0127 - val_acc: 0.9989
Epoch 262/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0278 - acc: 0.9974Epoch 00261: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0278 - acc: 0.9974 - val_loss: 0.0157 - val_acc: 0.9984
Epoch 263/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0409 - acc: 0.9961Epoch 00262: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0408 - acc: 0.9962 - val_loss: 0.0144 - val_acc: 0.9991
Epoch 264/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0273 - acc: 0.9973Epoch 00263: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0274 - acc: 0.9972 - val_loss: 0.0193 - val_acc: 0.9984
Epoch 265/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0214 - acc: 0.9971Epoch 00264: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0214 - acc: 0.9971 - val_loss: 0.0181 - val_acc: 0.9982
Epoch 266/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0256 - acc: 0.9972Epoch 00265: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0255 - acc: 0.9972 - val_loss: 0.0233 - val_acc: 0.9980
Epoch 267/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0246 - acc: 0.9972Epoch 00266: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0246 - acc: 0.9972 - val_loss: 0.0202 - val_acc: 0.9987
Epoch 268/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0253 - acc: 0.9973Epoch 00267: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0252 - acc: 0.9973 - val_loss: 0.0193 - val_acc: 0.9982
Epoch 269/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0264 - acc: 0.9973Epoch 00268: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0264 - acc: 0.9973 - val_loss: 0.0284 - val_acc: 0.9978
Epoch 270/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0339 - acc: 0.9967Epoch 00269: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0339 - acc: 0.9967 - val_loss: 0.0236 - val_acc: 0.9984
Epoch 271/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0377 - acc: 0.9966Epoch 00270: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0376 - acc: 0.9967 - val_loss: 0.0287 - val_acc: 0.9980
Epoch 272/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0268 - acc: 0.9969Epoch 00271: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0268 - acc: 0.9969 - val_loss: 0.0185 - val_acc: 0.9987
Epoch 273/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0369 - acc: 0.9965Epoch 00272: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0369 - acc: 0.9965 - val_loss: 0.0267 - val_acc: 0.9980
Epoch 274/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0414 - acc: 0.9960Epoch 00273: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0413 - acc: 0.9960 - val_loss: 0.0183 - val_acc: 0.9982
Epoch 275/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0363 - acc: 0.9963Epoch 00274: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0363 - acc: 0.9963 - val_loss: 0.0212 - val_acc: 0.9984
Epoch 276/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0301 - acc: 0.9967Epoch 00275: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0301 - acc: 0.9967 - val_loss: 0.0339 - val_acc: 0.9975
Epoch 277/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0194 - acc: 0.9974Epoch 00276: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0193 - acc: 0.9974 - val_loss: 0.0169 - val_acc: 0.9984
Epoch 278/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0250 - acc: 0.9969Epoch 00277: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0257 - acc: 0.9969 - val_loss: 0.0107 - val_acc: 0.9989
Epoch 279/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0263 - acc: 0.9973Epoch 00278: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0263 - acc: 0.9973 - val_loss: 0.0227 - val_acc: 0.9982
Epoch 280/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0140 - acc: 0.9985Epoch 00279: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0139 - acc: 0.9986 - val_loss: 0.0194 - val_acc: 0.9984
Epoch 281/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0231 - acc: 0.9972Epoch 00280: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0230 - acc: 0.9972 - val_loss: 0.0232 - val_acc: 0.9984
Epoch 282/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0336 - acc: 0.9967Epoch 00281: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0335 - acc: 0.9967 - val_loss: 0.0210 - val_acc: 0.9982
Epoch 283/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0170 - acc: 0.9979Epoch 00282: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0170 - acc: 0.9979 - val_loss: 0.0224 - val_acc: 0.9984
Epoch 284/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0179 - acc: 0.9978Epoch 00283: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0255 - val_acc: 0.9978
Epoch 285/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0244 - acc: 0.9974Epoch 00284: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0244 - acc: 0.9974 - val_loss: 0.0414 - val_acc: 0.9969
Epoch 286/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0203 - acc: 0.9973Epoch 00285: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0203 - acc: 0.9973 - val_loss: 0.0184 - val_acc: 0.9984
Epoch 287/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0151 - acc: 0.9979Epoch 00286: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0151 - acc: 0.9979 - val_loss: 0.0236 - val_acc: 0.9984
Epoch 288/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0261 - acc: 0.9973Epoch 00287: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0260 - acc: 0.9973 - val_loss: 0.0215 - val_acc: 0.9984
Epoch 289/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0200 - acc: 0.9978Epoch 00288: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0199 - acc: 0.9978 - val_loss: 0.0188 - val_acc: 0.9982
Epoch 290/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0256 - acc: 0.9973Epoch 00289: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0256 - acc: 0.9973 - val_loss: 0.0188 - val_acc: 0.9987
Epoch 291/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0282 - acc: 0.9973Epoch 00290: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0282 - acc: 0.9973 - val_loss: 0.0165 - val_acc: 0.9987
Epoch 292/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0175 - acc: 0.9979Epoch 00291: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0174 - acc: 0.9979 - val_loss: 0.0243 - val_acc: 0.9978
Epoch 293/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0219 - acc: 0.9978Epoch 00292: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0219 - acc: 0.9978 - val_loss: 0.0149 - val_acc: 0.9989
Epoch 294/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0198 - acc: 0.9980Epoch 00293: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0198 - acc: 0.9980 - val_loss: 0.0146 - val_acc: 0.9984
Epoch 295/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0343 - acc: 0.9965Epoch 00294: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0342 - acc: 0.9965 - val_loss: 0.0209 - val_acc: 0.9984
Epoch 296/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0314 - acc: 0.9968Epoch 00295: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0313 - acc: 0.9968 - val_loss: 0.0114 - val_acc: 0.9989
Epoch 297/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0143 - acc: 0.9985Epoch 00296: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0142 - acc: 0.9985 - val_loss: 0.0143 - val_acc: 0.9987
Epoch 298/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0129 - acc: 0.9986Epoch 00297: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0129 - acc: 0.9986 - val_loss: 0.0235 - val_acc: 0.9980
Epoch 299/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0292 - acc: 0.9967Epoch 00298: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0292 - acc: 0.9967 - val_loss: 0.0180 - val_acc: 0.9987
Epoch 300/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0126 - acc: 0.9982Epoch 00299: val_loss did not improve
17939/17939 [==============================] - 20s - loss: 0.0125 - acc: 0.9982 - val_loss: 0.0188 - val_acc: 0.9984
Epoch 301/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0141 - acc: 0.9983Epoch 00300: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0141 - acc: 0.9983 - val_loss: 0.0185 - val_acc: 0.9984
Epoch 302/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0129 - acc: 0.9986Epoch 00301: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0128 - acc: 0.9986 - val_loss: 0.0155 - val_acc: 0.9989
Epoch 303/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0202 - acc: 0.9978Epoch 00302: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0202 - acc: 0.9978 - val_loss: 0.0253 - val_acc: 0.9982
Epoch 304/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0198 - acc: 0.9980Epoch 00303: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0198 - acc: 0.9980 - val_loss: 0.0165 - val_acc: 0.9989
Epoch 305/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0193 - acc: 0.9973Epoch 00304: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0193 - acc: 0.9973 - val_loss: 0.0137 - val_acc: 0.9987
Epoch 306/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0250 - acc: 0.9977Epoch 00305: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0250 - acc: 0.9977 - val_loss: 0.0252 - val_acc: 0.9982
Epoch 307/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0252 - acc: 0.9973Epoch 00306: val_loss improved from 0.00749 to 0.00719, saving model to saved_models/weights.best.VGG16.hdf5_transfer_learning2
17939/17939 [==============================] - 21s - loss: 0.0251 - acc: 0.9973 - val_loss: 0.0072 - val_acc: 0.9996
Epoch 308/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0278 - acc: 0.9972Epoch 00307: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0278 - acc: 0.9972 - val_loss: 0.0094 - val_acc: 0.9991
Epoch 309/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0205 - acc: 0.9977Epoch 00308: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0205 - acc: 0.9977 - val_loss: 0.0174 - val_acc: 0.9989
Epoch 310/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0262 - acc: 0.9973Epoch 00309: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0261 - acc: 0.9973 - val_loss: 0.0179 - val_acc: 0.9989
Epoch 311/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0292 - acc: 0.9974Epoch 00310: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0292 - acc: 0.9974 - val_loss: 0.0139 - val_acc: 0.9987
Epoch 312/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0217 - acc: 0.9976Epoch 00311: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0217 - acc: 0.9976 - val_loss: 0.0245 - val_acc: 0.9982
Epoch 313/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0192 - acc: 0.9977Epoch 00312: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0192 - acc: 0.9977 - val_loss: 0.0095 - val_acc: 0.9991
Epoch 314/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0163 - acc: 0.9982Epoch 00313: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0163 - acc: 0.9982 - val_loss: 0.0190 - val_acc: 0.9984
Epoch 315/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0150 - acc: 0.9983Epoch 00314: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0149 - acc: 0.9983 - val_loss: 0.0121 - val_acc: 0.9989
Epoch 316/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0182 - acc: 0.9978Epoch 00315: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0182 - acc: 0.9978 - val_loss: 0.0144 - val_acc: 0.9991
Epoch 317/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0252 - acc: 0.9972Epoch 00316: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0252 - acc: 0.9972 - val_loss: 0.0133 - val_acc: 0.9989
Epoch 318/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0264 - acc: 0.9971Epoch 00317: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0264 - acc: 0.9971 - val_loss: 0.0138 - val_acc: 0.9989
Epoch 319/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0135 - acc: 0.9981Epoch 00318: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0135 - acc: 0.9981 - val_loss: 0.0144 - val_acc: 0.9991
Epoch 320/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0215 - acc: 0.9978Epoch 00319: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0215 - acc: 0.9978 - val_loss: 0.0097 - val_acc: 0.9989
Epoch 321/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0233 - acc: 0.9974Epoch 00320: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0232 - acc: 0.9974 - val_loss: 0.0138 - val_acc: 0.9989
Epoch 322/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0214 - acc: 0.9975Epoch 00321: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0213 - acc: 0.9975 - val_loss: 0.0137 - val_acc: 0.9989
Epoch 323/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0191 - acc: 0.9981Epoch 00322: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0191 - acc: 0.9981 - val_loss: 0.0133 - val_acc: 0.9989
Epoch 324/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0157 - acc: 0.9983Epoch 00323: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0157 - acc: 0.9983 - val_loss: 0.0114 - val_acc: 0.9989
Epoch 325/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0156 - acc: 0.9981Epoch 00324: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0156 - acc: 0.9981 - val_loss: 0.0130 - val_acc: 0.9989
Epoch 326/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0134 - acc: 0.9985Epoch 00325: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0134 - acc: 0.9985 - val_loss: 0.0178 - val_acc: 0.9987
Epoch 327/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0159 - acc: 0.9983Epoch 00326: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0159 - acc: 0.9983 - val_loss: 0.0182 - val_acc: 0.9984
Epoch 328/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0137 - acc: 0.9985Epoch 00327: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0136 - acc: 0.9985 - val_loss: 0.0233 - val_acc: 0.9982
Epoch 329/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0177 - acc: 0.9982Epoch 00328: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0176 - acc: 0.9982 - val_loss: 0.0236 - val_acc: 0.9980
Epoch 330/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0173 - acc: 0.9982Epoch 00329: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0173 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9987
Epoch 331/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0169 - acc: 0.9984Epoch 00330: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0169 - acc: 0.9984 - val_loss: 0.0172 - val_acc: 0.9989
Epoch 332/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0170 - acc: 0.9981Epoch 00331: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0170 - acc: 0.9981 - val_loss: 0.0240 - val_acc: 0.9980
Epoch 333/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0158 - acc: 0.9982Epoch 00332: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0158 - acc: 0.9982 - val_loss: 0.0165 - val_acc: 0.9984
Epoch 334/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0203 - acc: 0.9980Epoch 00333: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0202 - acc: 0.9980 - val_loss: 0.0227 - val_acc: 0.9984
Epoch 335/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0155 - acc: 0.9982Epoch 00334: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0155 - acc: 0.9982 - val_loss: 0.0186 - val_acc: 0.9987
Epoch 336/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0141 - acc: 0.9988Epoch 00335: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0141 - acc: 0.9988 - val_loss: 0.0164 - val_acc: 0.9984
Epoch 337/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0138 - acc: 0.9986Epoch 00336: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0138 - acc: 0.9986 - val_loss: 0.0121 - val_acc: 0.9991
Epoch 338/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0120 - acc: 0.9983Epoch 00337: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0120 - acc: 0.9983 - val_loss: 0.0221 - val_acc: 0.9984
Epoch 339/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0342 - acc: 0.9966Epoch 00338: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0342 - acc: 0.9966 - val_loss: 0.0110 - val_acc: 0.9991
Epoch 340/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0232 - acc: 0.9978Epoch 00339: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0232 - acc: 0.9978 - val_loss: 0.0178 - val_acc: 0.9984
Epoch 341/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0287 - acc: 0.9969Epoch 00340: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0287 - acc: 0.9969 - val_loss: 0.0184 - val_acc: 0.9984
Epoch 342/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0225 - acc: 0.9974Epoch 00341: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0225 - acc: 0.9974 - val_loss: 0.0217 - val_acc: 0.9982
Epoch 343/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0180 - acc: 0.9978Epoch 00342: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0180 - acc: 0.9978 - val_loss: 0.0237 - val_acc: 0.9978
Epoch 344/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0295 - acc: 0.9967Epoch 00343: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0295 - acc: 0.9967 - val_loss: 0.0082 - val_acc: 0.9993
Epoch 345/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0266 - acc: 0.9977Epoch 00344: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0265 - acc: 0.9977 - val_loss: 0.0223 - val_acc: 0.9978
Epoch 346/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0247 - acc: 0.9974Epoch 00345: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0247 - acc: 0.9974 - val_loss: 0.0105 - val_acc: 0.9991
Epoch 347/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0148 - acc: 0.9984Epoch 00346: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0148 - acc: 0.9984 - val_loss: 0.0149 - val_acc: 0.9987
Epoch 348/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0151 - acc: 0.9985Epoch 00347: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0151 - acc: 0.9986 - val_loss: 0.0181 - val_acc: 0.9984
Epoch 349/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0163 - acc: 0.9982Epoch 00348: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0163 - acc: 0.9982 - val_loss: 0.0110 - val_acc: 0.9991
Epoch 350/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0187 - acc: 0.9982Epoch 00349: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0186 - acc: 0.9982 - val_loss: 0.0104 - val_acc: 0.9991
Epoch 351/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0244 - acc: 0.9975Epoch 00350: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0243 - acc: 0.9975 - val_loss: 0.0103 - val_acc: 0.9991
Epoch 352/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0115 - acc: 0.9987Epoch 00351: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0115 - acc: 0.9987 - val_loss: 0.0202 - val_acc: 0.9984
Epoch 353/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0191 - acc: 0.9977Epoch 00352: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0190 - acc: 0.9977 - val_loss: 0.0107 - val_acc: 0.9991
Epoch 354/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0115 - acc: 0.9988Epoch 00353: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0115 - acc: 0.9988 - val_loss: 0.0155 - val_acc: 0.9987
Epoch 355/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0136 - acc: 0.9979Epoch 00354: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0136 - acc: 0.9979 - val_loss: 0.0134 - val_acc: 0.9989
Epoch 356/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0193 - acc: 0.9978Epoch 00355: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0193 - acc: 0.9978 - val_loss: 0.0207 - val_acc: 0.9987
Epoch 357/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0177 - acc: 0.9979Epoch 00356: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0177 - acc: 0.9979 - val_loss: 0.0073 - val_acc: 0.9996
Epoch 358/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0131 - acc: 0.9987Epoch 00357: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0131 - acc: 0.9987 - val_loss: 0.0198 - val_acc: 0.9984
Epoch 359/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0161 - acc: 0.9978Epoch 00358: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0161 - acc: 0.9978 - val_loss: 0.0158 - val_acc: 0.9989
Epoch 360/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0143 - acc: 0.9988Epoch 00359: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0143 - acc: 0.9988 - val_loss: 0.0073 - val_acc: 0.9996
Epoch 361/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0130 - acc: 0.9984Epoch 00360: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0136 - acc: 0.9984 - val_loss: 0.0224 - val_acc: 0.9982
Epoch 362/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0186 - acc: 0.9984Epoch 00361: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0186 - acc: 0.9984 - val_loss: 0.0181 - val_acc: 0.9987
Epoch 363/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0131 - acc: 0.9983Epoch 00362: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0131 - acc: 0.9983 - val_loss: 0.0153 - val_acc: 0.9987
Epoch 364/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0153 - acc: 0.9982Epoch 00363: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0153 - acc: 0.9982 - val_loss: 0.0073 - val_acc: 0.9996
Epoch 365/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0158 - acc: 0.9984Epoch 00364: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0158 - acc: 0.9984 - val_loss: 0.0090 - val_acc: 0.9991
Epoch 366/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0197 - acc: 0.9980Epoch 00365: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0197 - acc: 0.9980 - val_loss: 0.0287 - val_acc: 0.9978
Epoch 367/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0238 - acc: 0.9978Epoch 00366: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0238 - acc: 0.9978 - val_loss: 0.0123 - val_acc: 0.9991
Epoch 368/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0171 - acc: 0.9983Epoch 00367: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0171 - acc: 0.9983 - val_loss: 0.0202 - val_acc: 0.9984
Epoch 369/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0186 - acc: 0.9983Epoch 00368: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0186 - acc: 0.9983 - val_loss: 0.0126 - val_acc: 0.9991
Epoch 370/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0154 - acc: 0.9987Epoch 00369: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0154 - acc: 0.9987 - val_loss: 0.0179 - val_acc: 0.9987
Epoch 371/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0113 - acc: 0.9989Epoch 00370: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0113 - acc: 0.9989 - val_loss: 0.0190 - val_acc: 0.9980
Epoch 372/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0145 - acc: 0.9984Epoch 00371: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0145 - acc: 0.9984 - val_loss: 0.0096 - val_acc: 0.9989
Epoch 373/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0182 - acc: 0.9979Epoch 00372: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0182 - acc: 0.9979 - val_loss: 0.0141 - val_acc: 0.9987
Epoch 374/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0173 - acc: 0.9982Epoch 00373: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0175 - acc: 0.9981 - val_loss: 0.0116 - val_acc: 0.9989
Epoch 375/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0211 - acc: 0.9977Epoch 00374: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0211 - acc: 0.9977 - val_loss: 0.0174 - val_acc: 0.9987
Epoch 376/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0138 - acc: 0.9987Epoch 00375: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0138 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9989
Epoch 377/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0094 - acc: 0.9989Epoch 00376: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0094 - acc: 0.9989 - val_loss: 0.0108 - val_acc: 0.9989
Epoch 378/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0172 - acc: 0.9985Epoch 00377: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0171 - acc: 0.9985 - val_loss: 0.0133 - val_acc: 0.9989
Epoch 379/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0146 - acc: 0.9986Epoch 00378: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0146 - acc: 0.9986 - val_loss: 0.0108 - val_acc: 0.9991
Epoch 380/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0120 - acc: 0.9983Epoch 00379: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0120 - acc: 0.9983 - val_loss: 0.0134 - val_acc: 0.9991
Epoch 381/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0111 - acc: 0.9988Epoch 00380: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0111 - acc: 0.9988 - val_loss: 0.0219 - val_acc: 0.9982
Epoch 382/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0196 - acc: 0.9982Epoch 00381: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0196 - acc: 0.9982 - val_loss: 0.0113 - val_acc: 0.9991
Epoch 383/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0067 - acc: 0.9990Epoch 00382: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0086 - val_acc: 0.9991
Epoch 384/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0248 - acc: 0.9977Epoch 00383: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0248 - acc: 0.9977 - val_loss: 0.0144 - val_acc: 0.9991
Epoch 385/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0112 - acc: 0.9986Epoch 00384: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0112 - acc: 0.9986 - val_loss: 0.0185 - val_acc: 0.9987
Epoch 386/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0237 - acc: 0.9978Epoch 00385: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0239 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9984
Epoch 387/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0170 - acc: 0.9980Epoch 00386: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0170 - acc: 0.9980 - val_loss: 0.0081 - val_acc: 0.9991
Epoch 388/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0249 - acc: 0.9979Epoch 00387: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0248 - acc: 0.9979 - val_loss: 0.0146 - val_acc: 0.9991
Epoch 389/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0163 - acc: 0.9980Epoch 00388: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0163 - acc: 0.9980 - val_loss: 0.0119 - val_acc: 0.9987
Epoch 390/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0235 - acc: 0.9976Epoch 00389: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0235 - acc: 0.9976 - val_loss: 0.0198 - val_acc: 0.9984
Epoch 391/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0218 - acc: 0.9977Epoch 00390: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0218 - acc: 0.9977 - val_loss: 0.0113 - val_acc: 0.9991
Epoch 392/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0199 - acc: 0.9978Epoch 00391: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0199 - acc: 0.9978 - val_loss: 0.0206 - val_acc: 0.9987
Epoch 393/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0134 - acc: 0.9984Epoch 00392: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0134 - acc: 0.9984 - val_loss: 0.0244 - val_acc: 0.9980
Epoch 394/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0113 - acc: 0.9985Epoch 00393: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0113 - acc: 0.9985 - val_loss: 0.0198 - val_acc: 0.9987
Epoch 395/400
17904/17939 [============================&gt;.] - ETA: 0s - loss: 0.0157 - acc: 0.9985Epoch 00394: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0157 - acc: 0.9985 - val_loss: 0.0172 - val_acc: 0.9987
Epoch 396/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0141 - acc: 0.9983Epoch 00395: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0141 - acc: 0.9983 - val_loss: 0.0157 - val_acc: 0.9987
Epoch 397/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0109 - acc: 0.9987Epoch 00396: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0109 - acc: 0.9987 - val_loss: 0.0169 - val_acc: 0.9982
Epoch 398/400
17920/17939 [============================&gt;.] - ETA: 0s - loss: 0.0145 - acc: 0.9984Epoch 00397: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0145 - acc: 0.9984 - val_loss: 0.0274 - val_acc: 0.9980
Epoch 399/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0103 - acc: 0.9990Epoch 00398: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0103 - acc: 0.9990 - val_loss: 0.0126 - val_acc: 0.9989
Epoch 400/400
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0160 - acc: 0.9984Epoch 00399: val_loss did not improve
17939/17939 [==============================] - 21s - loss: 0.0160 - acc: 0.9984 - val_loss: 0.0072 - val_acc: 0.9996
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[33]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7f7adc1dff98&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_model2</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_transfer_learning2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>The model is tried on the test dataset of driver images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_predictions2</span> <span class="o">=</span> <span class="p">[</span><span class="n">VGG16_model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">bottleneck_features_test2_VGG16</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_subm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_files_final</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">VGG16_predictions2</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kaggle-Submission---VGG16-Transfer-Learning(Model-Architecture2)">Kaggle Submission - VGG16 Transfer Learning(Model Architecture2)<a class="anchor-link" href="#Kaggle-Submission---VGG16-Transfer-Learning(Model-Architecture2)">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_submission_2.csv&#39;</span><span class="p">,</span><span class="n">VGG16_subm2</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">comments</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">FileLink</span>
<span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_submission_2.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<a href='kaggle_submissions/VGG16_submission_2.csv' target='_blank'>kaggle_submissions/VGG16_submission_2.csv</a><br>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The submission resulted in Public Score of 5.21590. This can result in rank of 1416 out of 1440 in Public Leaderboard i.e. in top 98.33%</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step3'></a></p>
<h2 id="Step-3:-Train-a-CNN-with-Transfer-Learning---Part2">Step 3: Train a CNN with Transfer Learning - Part2<a class="anchor-link" href="#Step-3:-Train-a-CNN-with-Transfer-Learning---Part2">&#182;</a></h2><p>To improve accuracy, a CNN is trained using transfer learning.</p>
<h3 id="Fine-tuning-the-top-layers-of-a-a-pre-trained-network">Fine-tuning the top layers of a a pre-trained network<a class="anchor-link" href="#Fine-tuning-the-top-layers-of-a-a-pre-trained-network">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Instantiating-the-VGG16-base-for-Fine-Tuning">Instantiating the VGG16 base for Fine Tuning<a class="anchor-link" href="#Instantiating-the-VGG16-base-for-Fine-Tuning">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">VGG16</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">applications</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>

<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">VGG16</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, None, None, 3)     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, None, None, 64)    1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, None, None, 64)    36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, None, None, 64)    0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, None, None, 128)   73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, None, None, 128)   147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, None, None, 128)   0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, None, None, 256)   295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, None, None, 256)   590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, None, None, 256)   0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, None, None, 512)   0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, None, None, 512)   0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Architecture">Model Architecture<a class="anchor-link" href="#Model-Architecture">&#182;</a></h3><p>The model uses the the pre-trained VGG-16 model, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each driver category and is equipped with a softmax.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_top_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">VGG16_top_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">base_model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">VGG16_top_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_normal&#39;</span><span class="p">))</span>


<span class="n">VGG16_top_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_transfer_learning&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span> <span class="n">base_model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span> <span class="n">VGG16_top_model</span><span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="n">VGG16_top_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d_1 ( (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                5130      
=================================================================
Total params: 5,130
Trainable params: 5,130
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(&#34;in..., outputs=Tensor(&#34;se...)`
  
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3><p>Upto 15 layers of the VGG16 model were frozen so that the last convolutional block and the fully connected layer which is added to the top can be fine-tuned</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># set the first 15 layers (up to the last conv block)</span>
<span class="c1"># to non-trainable (weights will not be updated)</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="mi">15</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># compile the model with a SGD/momentum optimizer</span>
<span class="c1"># and a very slow learning rate.</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1">#model.compile(loss=&#39;categorical_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Train-the-Model">Train the Model<a class="anchor-link" href="#Train-the-Model">&#182;</a></h1><p>Fine-tuning is done with a very slow learning rate, and typically with the SGD optimizer rather than an adaptative learning rate optimizer such as RMSProp. This is to make sure that the magnitude of the updates stays very small, so as not to wreck the previously learned features.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_fine_tuning&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_tensors</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_tensors</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 17939 samples, validate on 4485 samples
Epoch 1/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.1573 - acc: 0.9573Epoch 00000: val_loss improved from inf to 0.03101, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 525s - loss: 0.1573 - acc: 0.9574 - val_loss: 0.0310 - val_acc: 0.9909
Epoch 2/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0174 - acc: 0.9949Epoch 00001: val_loss improved from 0.03101 to 0.01656, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 492s - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0166 - val_acc: 0.9955
Epoch 3/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 0.0029 - acc: 0.9993Epoch 00002: val_loss improved from 0.01656 to 0.00837, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 491s - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9978
Epoch 4/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 4.5108e-04 - acc: 1.0000Epoch 00003: val_loss improved from 0.00837 to 0.00799, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 492s - loss: 4.5100e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9975
Epoch 5/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 2.7549e-04 - acc: 1.0000Epoch 00004: val_loss improved from 0.00799 to 0.00772, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 492s - loss: 2.7635e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9973
Epoch 6/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 2.1916e-04 - acc: 1.0000Epoch 00005: val_loss did not improve
17939/17939 [==============================] - 491s - loss: 2.1922e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9975
Epoch 7/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 1.8481e-04 - acc: 1.0000Epoch 00006: val_loss improved from 0.00772 to 0.00770, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 491s - loss: 1.8479e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9978
Epoch 8/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 1.6181e-04 - acc: 1.0000Epoch 00007: val_loss improved from 0.00770 to 0.00758, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 492s - loss: 1.6178e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9973
Epoch 9/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 1.4491e-04 - acc: 1.0000Epoch 00008: val_loss improved from 0.00758 to 0.00751, saving model to saved_models/weights.best.VGG16.hdf5_fine_tuning
17939/17939 [==============================] - 491s - loss: 1.4489e-04 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9978
Epoch 10/10
17936/17939 [============================&gt;.] - ETA: 0s - loss: 1.3095e-04 - acc: 1.0000Epoch 00009: val_loss did not improve
17939/17939 [==============================] - 490s - loss: 1.3096e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9978
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7f5ae71edda0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;saved_models/weights.best.VGG16.hdf5_fine_tuning&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>The model is tried on the test dataset of driver images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_predictions_fine_tuned</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">test_tensors</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">VGG16_subm_fine_tuned</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_files_final</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">VGG16_predictions_fine_tuned</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kaggle-Submission---VGG16-Transfer-Learning(Fine-Tuning)">Kaggle Submission - VGG16 Transfer Learning(Fine Tuning)<a class="anchor-link" href="#Kaggle-Submission---VGG16-Transfer-Learning(Fine-Tuning)">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_fine_tuned_submission.csv&#39;</span><span class="p">,</span><span class="n">VGG16_subm_fine_tuned</span><span class="p">,</span> <span class="n">comments</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">FileLink</span>
<span class="n">FileLink</span><span class="p">(</span><span class="s1">&#39;kaggle_submissions/VGG16_fine_tuned_submission.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[14]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<a href='kaggle_submissions/VGG16_fine_tuned_submission.csv' target='_blank'>kaggle_submissions/VGG16_fine_tuned_submission.csv</a><br>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="The-submission-resulted-in-Public-Score-of-1.26397.-This-can-result-in-rank-of-617-out-of-1440-in-Public-Leaderboard-i.e.-in-top-42.84%">The submission resulted in Public Score of 1.26397. This can result in rank of 617 out of 1440 in Public Leaderboard i.e. in top 42.84%<a class="anchor-link" href="#The-submission-resulted-in-Public-Score-of-1.26397.-This-can-result-in-rank-of-617-out-of-1440-in-Public-Leaderboard-i.e.-in-top-42.84%">&#182;</a></h4>
</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
